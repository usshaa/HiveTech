{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0OdGCTHQWADHjnY3z8yVb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usshaa/HiveTech/blob/main/Synthetic_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Task 1: Generate dataset for Excel Fundamentals\n",
        "def generate_fundamentals_dataset():\n",
        "    data = {\n",
        "        'Month': [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"],\n",
        "        'Sales': np.random.randint(1000, 10000, 12),\n",
        "        'Expenses': np.random.randint(500, 7000, 12),\n",
        "        'Profit': lambda df: df['Sales'] - df['Expenses']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df['Profit'] = df['Sales'] - df['Expenses']\n",
        "    df.to_csv('unit1_fundamentals.csv', index=False)\n",
        "\n",
        "# Task 2: Generate dataset for Advanced Excel Functions\n",
        "def generate_advanced_functions_dataset():\n",
        "    data = {\n",
        "        'Year': np.arange(2015, 2026),\n",
        "        'Sales': np.random.randint(5000, 20000, 11),\n",
        "        'Forecasted Sales': lambda df: df['Sales'] * np.random.uniform(1.05, 1.2, 11)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df['Forecasted Sales'] = df['Sales'] * np.random.uniform(1.05, 1.2, 11)\n",
        "    df.to_csv('unit2_advanced_functions.csv', index=False)\n",
        "\n",
        "# Task 3: Generate dataset for Lookup, Financial, and Statistical Functions\n",
        "def generate_lookup_financial_dataset():\n",
        "    employee_ids = [f\"EMP{str(i).zfill(3)}\" for i in range(1, 101)]\n",
        "    salaries = np.random.randint(30000, 120000, 100)\n",
        "    departments = random.choices(['HR', 'Finance', 'IT', 'Sales', 'Marketing'], k=100)\n",
        "    df = pd.DataFrame({'Employee ID': employee_ids, 'Department': departments, 'Salary': salaries})\n",
        "    df.to_csv('unit3_lookup_financial.csv', index=False)\n",
        "\n",
        "# Task 4: Generate dataset for Data Analysis and Visualization\n",
        "def generate_data_analysis_dataset():\n",
        "    categories = ['Electronics', 'Clothing', 'Home Decor', 'Toys', 'Books']\n",
        "    ratings = np.random.randint(1, 6, 100)\n",
        "    df = pd.DataFrame({'Product Category': random.choices(categories, k=100), 'Rating': ratings})\n",
        "    df.to_csv('unit4_data_analysis.csv', index=False)\n",
        "\n",
        "# Task 5: Generate dataset for PivotTables and Dashboard Creation\n",
        "def generate_dashboard_dataset():\n",
        "    dates = [datetime.today() - timedelta(days=i) for i in range(365)]\n",
        "    sales = np.random.randint(500, 5000, 365)\n",
        "    categories = random.choices(['Electronics', 'Grocery', 'Fashion', 'Furniture', 'Automobile'], k=365)\n",
        "    df = pd.DataFrame({'Date': dates, 'Sales': sales, 'Category': categories})\n",
        "    df.to_csv('unit5_dashboard.csv', index=False)\n",
        "\n",
        "# Run all functions\n",
        "generate_fundamentals_dataset()\n",
        "generate_advanced_functions_dataset()\n",
        "generate_lookup_financial_dataset()\n",
        "generate_data_analysis_dataset()\n",
        "generate_dashboard_dataset()\n",
        "\n",
        "print(\"All datasets have been generated and saved as CSV files.\")\n"
      ],
      "metadata": {
        "id": "-crN1mRSTUnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06684f2e-2028-44d3-d7d7-fff948c18ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All datasets have been generated and saved as CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a Python script that generates a synthetic retail sales dataset for your **Retail Sales Analytics & Forecast Dashboard** project. The script ensures the data follows real-world trends, such as:  \n",
        "\n",
        "âœ… **Seasonal patterns** (higher sales during holidays, lower in off-seasons)  \n",
        "âœ… **Store performance variations** (some stores performing better than others)  \n",
        "âœ… **Product category sales behavior** (essentials selling consistently, luxury items fluctuating)  \n",
        "âœ… **Logical date-based sales trends** (weekends having higher footfall)  \n",
        "\n",
        "The dataset includes **1000+ records over 2 years**, covering:  \n",
        "- **Sales Date**  \n",
        "- **Store ID** (multiple stores)  \n",
        "- **Product ID** (diverse product categories)  \n",
        "- **Category** (Electronics, Grocery, Clothing, etc.)  \n",
        "- **Units Sold**  \n",
        "- **Unit Price**  \n",
        "- **Revenue** (calculated)  \n",
        "- **Cost Price**  \n",
        "- **Profit Margin**  \n",
        "- **Discount Given** (seasonal logic applied)  \n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Œ Python Code to Generate the Dataset:\n",
        "\n",
        "```python"
      ],
      "metadata": {
        "id": "kLWHPm3ZaEVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define date range (2 years of data)\n",
        "start_date = datetime(2022, 1, 1)\n",
        "end_date = datetime(2023, 12, 31)\n",
        "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# Store and Product Details\n",
        "store_ids = [f\"Store_{i}\" for i in range(1, 6)]  # 5 stores\n",
        "categories = [\"Electronics\", \"Grocery\", \"Clothing\", \"Furniture\", \"Beauty\"]\n",
        "products = {\n",
        "    \"Electronics\": [\"Laptop\", \"Smartphone\", \"Headphones\", \"Smartwatch\"],\n",
        "    \"Grocery\": [\"Milk\", \"Eggs\", \"Bread\", \"Rice\", \"Cereal\"],\n",
        "    \"Clothing\": [\"T-Shirts\", \"Jeans\", \"Jackets\", \"Shoes\"],\n",
        "    \"Furniture\": [\"Chair\", \"Table\", \"Couch\", \"Bed\"],\n",
        "    \"Beauty\": [\"Shampoo\", \"Perfume\", \"Lotion\", \"Makeup\"]\n",
        "}\n",
        "\n",
        "# Define seasonal trends (higher sales during certain months)\n",
        "seasonal_multiplier = {\n",
        "    1: 0.8,  2: 0.9,  3: 1.0,  4: 1.1,  5: 1.2,  6: 1.3,\n",
        "    7: 1.4,  8: 1.2,  9: 1.0, 10: 1.1, 11: 1.3, 12: 1.5\n",
        "}\n",
        "\n",
        "# Generate Sales Data\n",
        "sales_data = []\n",
        "\n",
        "for date in date_range:\n",
        "    for store in store_ids:\n",
        "        for category in categories:\n",
        "            for product in products[category]:\n",
        "                # Logical sales trends\n",
        "                base_sales = np.random.randint(5, 50)  # Base units sold\n",
        "                season_factor = seasonal_multiplier[date.month]  # Seasonal effect\n",
        "                units_sold = int(base_sales * season_factor * (1 if date.weekday() < 5 else 1.2))  # More sales on weekends\n",
        "\n",
        "                unit_price = np.random.uniform(5, 500)  # Price range\n",
        "                cost_price = unit_price * np.random.uniform(0.6, 0.8)  # Cost is 60-80% of price\n",
        "\n",
        "                revenue = units_sold * unit_price\n",
        "                cost = units_sold * cost_price\n",
        "                profit_margin = revenue - cost\n",
        "\n",
        "                discount = 0\n",
        "                if date.month in [11, 12] or np.random.rand() > 0.8:  # Higher discount during holidays\n",
        "                    discount = np.random.uniform(5, 20) if revenue > 100 else np.random.uniform(1, 5)\n",
        "                    revenue -= discount\n",
        "\n",
        "                sales_data.append([date, store, category, product, units_sold, unit_price, revenue, cost_price, profit_margin, discount])\n",
        "\n",
        "# Create DataFrame\n",
        "df_sales = pd.DataFrame(sales_data, columns=[\n",
        "    \"Date\", \"Store_ID\", \"Category\", \"Product\", \"Units_Sold\", \"Unit_Price\",\n",
        "    \"Revenue\", \"Cost_Price\", \"Profit_Margin\", \"Discount_Given\"\n",
        "])\n",
        "\n",
        "# Save to CSV\n",
        "df_sales.to_csv(\"retail_sales_data.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic retail sales dataset generated successfully!\")"
      ],
      "metadata": {
        "id": "EoCZOfq3Z620",
        "outputId": "d90542e9-2bc0-4c78-f4db-26a08610f3a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic retail sales dataset generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”¹ Features of This Dataset:\n",
        "âœ” **Seasonal Sales Pattern**: Sales increase in peak seasons (Nov-Dec, summer months)  \n",
        "âœ” **Weekend Boost**: Higher sales on weekends than weekdays  \n",
        "âœ” **Category-Specific Pricing**: Electronics have higher prices, groceries lower  \n",
        "âœ” **Discounts Applied Logically**: High during holidays, random otherwise  \n",
        "âœ” **Profit Margins Computed**: Based on cost vs. selling price  \n",
        "\n",
        "This dataset will work perfectly with **Excel pivot tables, slicers, and forecasting models** as required in your project. Let me know if you need modifications! ðŸš€"
      ],
      "metadata": {
        "id": "O9hFX_oCZ-Ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a **Python script** to generate **synthetic financial portfolio data** for the **Financial Portfolio Analysis & Retirement Planning Tool** project. This script ensures logical structuring of the dataset, simulating **realistic stock/bond investments, returns, risk metrics, and historical prices.**  \n",
        "\n",
        "---\n",
        "\n",
        "### **Synthetic Data Generation Overview**  \n",
        "- **Investment Portfolio Data**: 50 investments (stocks, bonds, mutual funds) with risk and return metrics over **5 years**  \n",
        "- **Historical Prices & Dividends**: Simulated **monthly** prices and **quarterly dividends**  \n",
        "- **Retirement Savings Plan**: Simulated savings, withdrawals, and pension/lump sum options  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script to Generate Synthetic Data**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "T34FftVQfgN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define the number of investments and years of data\n",
        "num_investments = 50\n",
        "years = 5\n",
        "start_date = datetime(2019, 1, 1)\n",
        "\n",
        "# Generate Investment Portfolio Data\n",
        "investment_types = [\"Stock\", \"Bond\", \"Mutual Fund\", \"ETF\"]\n",
        "sectors = [\"Technology\", \"Healthcare\", \"Finance\", \"Energy\", \"Consumer Goods\", \"Utilities\"]\n",
        "risk_categories = [\"Low\", \"Medium\", \"High\"]\n",
        "\n",
        "portfolio_data = []\n",
        "for i in range(1, num_investments + 1):\n",
        "    investment = {\n",
        "        \"Investment_ID\": f\"INV{i:03}\",\n",
        "        \"Investment_Type\": random.choice(investment_types),\n",
        "        \"Sector\": random.choice(sectors),\n",
        "        \"Risk_Level\": random.choice(risk_categories),\n",
        "        \"Initial_Investment\": round(random.uniform(1000, 10000), 2),\n",
        "        \"Annual_Return (%)\": round(random.uniform(-5, 15), 2),\n",
        "        \"Standard_Deviation (%)\": round(random.uniform(2, 20), 2),\n",
        "        \"Current_Value\": round(random.uniform(1200, 15000), 2),\n",
        "        \"Dividend_Yield (%)\": round(random.uniform(0, 5), 2),\n",
        "    }\n",
        "    portfolio_data.append(investment)\n",
        "\n",
        "portfolio_df = pd.DataFrame(portfolio_data)\n",
        "portfolio_df.to_csv(\"Investment_Portfolio.csv\", index=False)\n",
        "print(\"Investment Portfolio Data Saved!\")\n",
        "\n",
        "# Generate Historical Price and Dividend Data\n",
        "historical_data = []\n",
        "for i in range(1, num_investments + 1):\n",
        "    start_price = round(random.uniform(50, 500), 2)\n",
        "    for j in range(years * 12):  # Monthly Data\n",
        "        date = start_date + timedelta(days=30 * j)\n",
        "        monthly_return = random.uniform(-0.05, 0.1)  # Monthly price fluctuation\n",
        "        price = round(start_price * (1 + monthly_return), 2)\n",
        "        dividend = round(price * (random.uniform(0, 0.02)), 2) if j % 3 == 0 else 0  # Quarterly dividends\n",
        "\n",
        "        historical_data.append({\n",
        "            \"Investment_ID\": f\"INV{i:03}\",\n",
        "            \"Date\": date.strftime(\"%Y-%m-%d\"),\n",
        "            \"Closing_Price\": price,\n",
        "            \"Dividend\": dividend,\n",
        "        })\n",
        "        start_price = price  # Update price for next month\n",
        "\n",
        "historical_df = pd.DataFrame(historical_data)\n",
        "historical_df.to_csv(\"Investment_Historical_Prices.csv\", index=False)\n",
        "print(\"Historical Prices & Dividend Data Saved!\")\n",
        "\n",
        "# Generate Retirement Planning Data\n",
        "retirement_data = []\n",
        "ages = list(range(30, 66, 5))  # Age groups from 30 to 65\n",
        "for age in ages:\n",
        "    retirement_data.append({\n",
        "        \"Age\": age,\n",
        "        \"Annual_Contribution ($)\": round(random.uniform(5000, 20000), 2),\n",
        "        \"Investment_Growth_Rate (%)\": round(random.uniform(4, 10), 2),\n",
        "        \"Projected_Retirement_Fund ($)\": round(random.uniform(200000, 2000000), 2),\n",
        "        \"Annual_Withdrawal ($)\": round(random.uniform(15000, 60000), 2),\n",
        "        \"Pension_Option\": random.choice([\"Yes\", \"No\"]),\n",
        "        \"Lump_Sum_Option ($)\": round(random.uniform(100000, 800000), 2) if random.choice([True, False]) else 0,\n",
        "    })\n",
        "\n",
        "retirement_df = pd.DataFrame(retirement_data)\n",
        "retirement_df.to_csv(\"Retirement_Planning.csv\", index=False)\n",
        "print(\"Retirement Planning Data Saved!\")"
      ],
      "metadata": {
        "id": "pNlPMbGQZ86M",
        "outputId": "2ab87ca2-41e7-40b7-a993-abfa7a806dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Investment Portfolio Data Saved!\n",
            "Historical Prices & Dividend Data Saved!\n",
            "Retirement Planning Data Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated CSV Files**\n",
        "1. **Investment_Portfolio.csv** â†’ Portfolio with risk, return, and valuation  \n",
        "2. **Investment_Historical_Prices.csv** â†’ Monthly prices and quarterly dividends for 5 years  \n",
        "3. **Retirement_Planning.csv** â†’ Contribution, withdrawal, pension & lump sum data  \n",
        "\n",
        "This dataset can be **imported into Excel** for advanced **financial analysis, pivot tables, and scenario modeling**. ðŸš€ Let me know if you need modifications!"
      ],
      "metadata": {
        "id": "5wFMf_GEf2xO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hereâ€™s a **Python script** to generate **synthetic HR analytics data** for the **HR Analytics & Workforce Planning Dashboard** project. The script logically creates workforce demographics, salaries, attrition risk factors, and performance metrics for **500 employees.**  \n",
        "\n",
        "---\n",
        "\n",
        "### **Synthetic Data Generation Overview**  \n",
        "- **Employee Master List**: 500 employees with **ID, department, role, age, gender, tenure, and performance ratings**  \n",
        "- **Compensation Data**: Salaries, bonuses, and **compliance with market benchmarks**  \n",
        "- **Attrition Risk Indicators**: Tenure, performance, workload, **past turnover trends**  \n",
        "- **Workforce Planning**: Forecasting headcount growth & retirement eligibility  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script to Generate Synthetic HR Data**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "lN2j2Y4Ig3Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define parameters\n",
        "num_employees = 500\n",
        "departments = [\"HR\", \"Finance\", \"IT\", \"Marketing\", \"Sales\", \"Operations\"]\n",
        "roles = {\n",
        "    \"HR\": [\"HR Manager\", \"Recruiter\", \"HR Assistant\"],\n",
        "    \"Finance\": [\"Accountant\", \"Financial Analyst\", \"Payroll Manager\"],\n",
        "    \"IT\": [\"Software Engineer\", \"Data Analyst\", \"IT Support\"],\n",
        "    \"Marketing\": [\"Marketing Manager\", \"SEO Specialist\", \"Content Writer\"],\n",
        "    \"Sales\": [\"Sales Executive\", \"Account Manager\", \"Business Developer\"],\n",
        "    \"Operations\": [\"Operations Manager\", \"Supply Chain Analyst\", \"Logistics Coordinator\"],\n",
        "}\n",
        "genders = [\"Male\", \"Female\", \"Non-Binary\"]\n",
        "performance_ratings = [\"Low\", \"Average\", \"High\", \"Excellent\"]\n",
        "\n",
        "# Generate Employee Data\n",
        "employees = []\n",
        "start_date = datetime(2000, 1, 1)\n",
        "\n",
        "for i in range(1, num_employees + 1):\n",
        "    dept = random.choice(departments)\n",
        "    role = random.choice(roles[dept])\n",
        "    age = random.randint(22, 60)\n",
        "    gender = random.choice(genders)\n",
        "    tenure = random.randint(1, 40)  # Years with the company\n",
        "    salary = round(random.uniform(30000, 120000), 2)  # Annual Salary\n",
        "    bonus = round(salary * random.uniform(0.05, 0.2), 2)  # Bonus Percentage\n",
        "    performance = random.choice(performance_ratings)\n",
        "    attrition_risk = round(random.uniform(0, 1), 2)  # Probability of leaving\n",
        "    workload_index = round(random.uniform(0.5, 1.5), 2)  # Higher values indicate workload stress\n",
        "    last_promotion = random.randint(0, 10)  # Years since last promotion\n",
        "    retirement_eligibility = \"Yes\" if age >= 58 else \"No\"\n",
        "\n",
        "    employees.append({\n",
        "        \"Employee_ID\": f\"EMP{i:03}\",\n",
        "        \"Department\": dept,\n",
        "        \"Role\": role,\n",
        "        \"Age\": age,\n",
        "        \"Gender\": gender,\n",
        "        \"Tenure (Years)\": tenure,\n",
        "        \"Salary ($)\": salary,\n",
        "        \"Bonus ($)\": bonus,\n",
        "        \"Performance_Rating\": performance,\n",
        "        \"Attrition_Risk (%)\": attrition_risk * 100,\n",
        "        \"Workload_Index\": workload_index,\n",
        "        \"Last_Promotion (Years Ago)\": last_promotion,\n",
        "        \"Retirement_Eligible\": retirement_eligibility,\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and Save\n",
        "employee_df = pd.DataFrame(employees)\n",
        "employee_df.to_csv(\"HR_Employee_Data.csv\", index=False)\n",
        "print(\"HR Employee Data Saved!\")\n",
        "\n",
        "# Generate Workforce Planning Data (Headcount Projections)\n",
        "future_years = [2024, 2025, 2026, 2027, 2028]\n",
        "headcount_projections = []\n",
        "for dept in departments:\n",
        "    for year in future_years:\n",
        "        growth_rate = random.uniform(1.02, 1.10)  # 2% to 10% growth\n",
        "        projected_headcount = int(num_employees * growth_rate)\n",
        "\n",
        "        headcount_projections.append({\n",
        "            \"Year\": year,\n",
        "            \"Department\": dept,\n",
        "            \"Projected_Headcount\": projected_headcount,\n",
        "            \"Retirement_Count\": random.randint(5, 20),  # Expected retirements\n",
        "            \"New_Hires_Needed\": max(0, projected_headcount - num_employees),\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame and Save\n",
        "headcount_df = pd.DataFrame(headcount_projections)\n",
        "headcount_df.to_csv(\"Workforce_Headcount_Projections.csv\", index=False)\n",
        "print(\"Workforce Headcount Projections Saved!\")\n",
        "\n",
        "# Generate Compensation Analysis Data (Market Comparison)\n",
        "compensation_analysis = []\n",
        "for i in range(1, num_employees + 1):\n",
        "    market_salary = round(random.uniform(35000, 110000), 2)  # Industry benchmark\n",
        "    salary = employee_df.iloc[i - 1][\"Salary ($)\"]\n",
        "    compa_ratio = round(salary / market_salary, 2)  # Salary compared to market\n",
        "\n",
        "    compensation_analysis.append({\n",
        "        \"Employee_ID\": f\"EMP{i:03}\",\n",
        "        \"Current_Salary ($)\": salary,\n",
        "        \"Market_Salary ($)\": market_salary,\n",
        "        \"Compa-Ratio\": compa_ratio,  # >1 = Overpaid, <1 = Underpaid\n",
        "        \"Equity_Adjustment_Needed ($)\": round(market_salary - salary, 2),\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and Save\n",
        "comp_df = pd.DataFrame(compensation_analysis)\n",
        "comp_df.to_csv(\"Compensation_Analysis.csv\", index=False)\n",
        "print(\"Compensation Analysis Data Saved!\")"
      ],
      "metadata": {
        "id": "S9kAsnuWf2Kl",
        "outputId": "e056d61a-8efe-4669-aebd-c27748029a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HR Employee Data Saved!\n",
            "Workforce Headcount Projections Saved!\n",
            "Compensation Analysis Data Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Generated CSV Files**\n",
        "1. **HR_Employee_Data.csv** â†’ Employee records with demographics, salary, performance, attrition risk  \n",
        "2. **Workforce_Headcount_Projections.csv** â†’ Future workforce demand & hiring needs  \n",
        "3. **Compensation_Analysis.csv** â†’ Salary comparisons and equity adjustments  \n",
        "\n",
        "This dataset is ready for **Excel-based pivot tables, workforce planning, and HR analytics!** ðŸš€ Let me know if you need modifications!"
      ],
      "metadata": {
        "id": "fYP9GKrihBkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hereâ€™s a **Python script** to generate **synthetic supply chain data** for the **Supply Chain Analytics & Inventory Optimization System** project. The script logically creates **inventory, supplier, and demand forecasting datasets** for **1,000 products** across multiple warehouses.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Synthetic Data Generation Overview**  \n",
        "- **Product & Inventory Data**: 1,000 SKUs with **category, stock levels, reorder points, lead times**  \n",
        "- **Supplier Data**: Performance scores, delivery times, cost analysis  \n",
        "- **Demand Forecasting**: Time-series data for demand prediction  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script to Generate Synthetic Supply Chain Data**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "TfpXY5chjXHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define parameters\n",
        "num_products = 1000\n",
        "num_suppliers = 50\n",
        "categories = [\"Electronics\", \"Furniture\", \"Clothing\", \"Groceries\", \"Automotive\", \"Pharmaceuticals\"]\n",
        "warehouses = [\"Warehouse A\", \"Warehouse B\", \"Warehouse C\"]\n",
        "suppliers = [f\"Supplier_{i}\" for i in range(1, num_suppliers + 1)]\n",
        "\n",
        "# Generate Product & Inventory Data\n",
        "products = []\n",
        "for i in range(1, num_products + 1):\n",
        "    category = random.choice(categories)\n",
        "    product_id = f\"P{i:04}\"\n",
        "    product_name = f\"{category}_Product_{i}\"\n",
        "    warehouse = random.choice(warehouses)\n",
        "    stock_level = random.randint(10, 500)  # Current inventory level\n",
        "    reorder_point = random.randint(20, 100)  # When to reorder\n",
        "    safety_stock = reorder_point * random.uniform(0.5, 1.5)  # Safety buffer stock\n",
        "    lead_time_days = random.randint(3, 30)  # Supplier lead time\n",
        "    turnover_rate = round(random.uniform(3.0, 12.0), 2)  # Inventory turnover rate\n",
        "    cost_per_unit = round(random.uniform(5.0, 500.0), 2)\n",
        "\n",
        "    products.append({\n",
        "        \"Product_ID\": product_id,\n",
        "        \"Product_Name\": product_name,\n",
        "        \"Category\": category,\n",
        "        \"Warehouse\": warehouse,\n",
        "        \"Stock_Level\": stock_level,\n",
        "        \"Reorder_Point\": reorder_point,\n",
        "        \"Safety_Stock\": round(safety_stock),\n",
        "        \"Lead_Time (Days)\": lead_time_days,\n",
        "        \"Turnover_Rate\": turnover_rate,\n",
        "        \"Cost_Per_Unit ($)\": cost_per_unit,\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "inventory_df = pd.DataFrame(products)\n",
        "inventory_df.to_csv(\"Inventory_Data.csv\", index=False)\n",
        "print(\"Inventory Data Saved!\")\n",
        "\n",
        "# Generate Supplier Performance Data\n",
        "supplier_performance = []\n",
        "for supplier in suppliers:\n",
        "    on_time_delivery = round(random.uniform(80, 100), 2)  # On-time delivery percentage\n",
        "    quality_rating = round(random.uniform(3.0, 5.0), 2)  # Out of 5\n",
        "    avg_lead_time = random.randint(5, 25)  # Average delivery time\n",
        "    cost_variance = round(random.uniform(0.90, 1.10), 2)  # Cost fluctuation\n",
        "    total_orders = random.randint(50, 500)  # Orders fulfilled\n",
        "\n",
        "    supplier_performance.append({\n",
        "        \"Supplier_Name\": supplier,\n",
        "        \"On_Time_Delivery (%)\": on_time_delivery,\n",
        "        \"Quality_Rating (out of 5)\": quality_rating,\n",
        "        \"Avg_Lead_Time (Days)\": avg_lead_time,\n",
        "        \"Cost_Variance\": cost_variance,\n",
        "        \"Total_Orders_Fulfilled\": total_orders,\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "supplier_df = pd.DataFrame(supplier_performance)\n",
        "supplier_df.to_csv(\"Supplier_Performance.csv\", index=False)\n",
        "print(\"Supplier Performance Data Saved!\")\n",
        "\n",
        "# Generate Demand Forecasting Data (Time Series)\n",
        "start_date = datetime(2023, 1, 1)\n",
        "forecasting_data = []\n",
        "\n",
        "for i in range(1, num_products + 1):\n",
        "    product_id = f\"P{i:04}\"\n",
        "    date = start_date\n",
        "\n",
        "    for _ in range(365):  # Generate daily demand for a year\n",
        "        demand = max(0, int(np.random.normal(50, 20)))  # Normal distribution\n",
        "        forecasting_data.append({\"Date\": date.strftime(\"%Y-%m-%d\"), \"Product_ID\": product_id, \"Demand\": demand})\n",
        "        date += timedelta(days=1)\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "forecast_df = pd.DataFrame(forecasting_data)\n",
        "forecast_df.to_csv(\"Demand_Forecasting.csv\", index=False)\n",
        "print(\"Demand Forecasting Data Saved!\")\n"
      ],
      "metadata": {
        "id": "f1E0l-SNg_YL",
        "outputId": "38efd350-cd9a-457a-a272-8885651c37a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inventory Data Saved!\n",
            "Supplier Performance Data Saved!\n",
            "Demand Forecasting Data Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Generated CSV Files**\n",
        "1. **Inventory_Data.csv** â†’ Product information with stock levels, reorder points, safety stock, lead time  \n",
        "2. **Supplier_Performance.csv** â†’ Supplier scorecards for delivery, cost, and reliability  \n",
        "3. **Demand_Forecasting.csv** â†’ Time-series demand data for forecasting models  \n",
        "\n",
        "This dataset is **Excel-ready** for **pivot tables, inventory forecasting, and supplier analysis!** ðŸš€ Let me know if you need modifications!"
      ],
      "metadata": {
        "id": "4o8T7OyLjfW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Marketing Campaign Data**  \n",
        "This script generates **synthetic marketing data** for the **Marketing Campaign Analytics & ROI Optimization** project. It includes **campaign performance, customer response patterns, and financial ROI calculations** for **20 campaigns and 5,000 customers**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Synthetic Data Generation Overview**  \n",
        "âœ… **Marketing Campaigns**: 20 campaigns across different channels (Social Media, Email, TV, etc.)  \n",
        "âœ… **Customer Data**: 5,000 customers with demographic and purchase details  \n",
        "âœ… **Campaign Metrics**: Conversion rates, CPA (Cost per Acquisition), Click-through rates  \n",
        "âœ… **Financial Analysis**: ROI, ROMI (Return on Marketing Investment), NPV (Net Present Value)  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python"
      ],
      "metadata": {
        "id": "8Ich5aYHkMsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define parameters\n",
        "num_customers = 5000\n",
        "num_campaigns = 20\n",
        "channels = [\"Social Media\", \"Email\", \"TV\", \"Google Ads\", \"Radio\", \"Billboards\"]\n",
        "campaign_types = [\"Awareness\", \"Engagement\", \"Lead Generation\", \"Retention\"]\n",
        "industries = [\"Retail\", \"Finance\", \"Healthcare\", \"Technology\", \"Automotive\"]\n",
        "customer_segments = [\"New\", \"Returning\", \"Loyal\"]\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "# Generate Marketing Campaign Data\n",
        "campaigns = []\n",
        "for i in range(1, num_campaigns + 1):\n",
        "    campaign_id = f\"C{i:03}\"\n",
        "    campaign_name = f\"Campaign_{i}\"\n",
        "    channel = random.choice(channels)\n",
        "    campaign_type = random.choice(campaign_types)\n",
        "    start_date = datetime(2023, random.randint(1, 12), random.randint(1, 28))\n",
        "    budget = round(random.uniform(5000, 100000), 2)\n",
        "    impressions = random.randint(10000, 1000000)\n",
        "    clicks = random.randint(500, impressions // 10)  # Clicks must be lower than impressions\n",
        "    conversions = random.randint(50, clicks // 5)  # Conversions must be lower than clicks\n",
        "    cpa = round(budget / max(conversions, 1), 2)  # Cost per acquisition\n",
        "    revenue = conversions * round(random.uniform(50, 500), 2)  # Revenue per conversion\n",
        "    roi = round((revenue - budget) / budget, 2)  # ROI Calculation\n",
        "\n",
        "    campaigns.append({\n",
        "        \"Campaign_ID\": campaign_id,\n",
        "        \"Campaign_Name\": campaign_name,\n",
        "        \"Channel\": channel,\n",
        "        \"Campaign_Type\": campaign_type,\n",
        "        \"Start_Date\": start_date.strftime(\"%Y-%m-%d\"),\n",
        "        \"Budget ($)\": budget,\n",
        "        \"Impressions\": impressions,\n",
        "        \"Clicks\": clicks,\n",
        "        \"Conversions\": conversions,\n",
        "        \"CPA ($)\": cpa,\n",
        "        \"Revenue ($)\": revenue,\n",
        "        \"ROI\": roi\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "campaigns_df = pd.DataFrame(campaigns)\n",
        "campaigns_df.to_csv(\"Marketing_Campaigns.csv\", index=False)\n",
        "print(\"Marketing Campaign Data Saved!\")\n",
        "\n",
        "# Generate Customer Response Data\n",
        "customers = []\n",
        "for i in range(1, num_customers + 1):\n",
        "    customer_id = f\"Cust{i:04}\"\n",
        "    age = random.randint(18, 65)\n",
        "    gender = random.choice([\"Male\", \"Female\", \"Other\"])\n",
        "    industry = random.choice(industries)\n",
        "    segment = random.choice(customer_segments)\n",
        "    campaign_id = random.choice([f\"C{random.randint(1, num_campaigns):03}\"])\n",
        "    engagement_score = round(random.uniform(0, 1), 2)  # Engagement Score (0-1)\n",
        "    conversion = random.choice([0, 1]) if engagement_score > 0.5 else 0  # Likely conversion if engaged\n",
        "    lifetime_value = round(random.uniform(100, 5000), 2)  # Customer LTV\n",
        "\n",
        "    customers.append({\n",
        "        \"Customer_ID\": customer_id,\n",
        "        \"Age\": age,\n",
        "        \"Gender\": gender,\n",
        "        \"Industry\": industry,\n",
        "        \"Segment\": segment,\n",
        "        \"Campaign_ID\": campaign_id,\n",
        "        \"Engagement_Score\": engagement_score,\n",
        "        \"Converted\": conversion,\n",
        "        \"Customer_LTV ($)\": lifetime_value\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "customers_df = pd.DataFrame(customers)\n",
        "customers_df.to_csv(\"Customer_Responses.csv\", index=False)\n",
        "print(\"Customer Response Data Saved!\")\n",
        "\n",
        "# Generate Time-Series Data for Campaign Forecasting\n",
        "forecasting_data = []\n",
        "date = datetime(2023, 1, 1)\n",
        "\n",
        "for _ in range(365):  # 1 year of data\n",
        "    campaign_id = f\"C{random.randint(1, num_campaigns):03}\"\n",
        "    daily_spend = round(random.uniform(100, 5000), 2)\n",
        "    daily_clicks = random.randint(50, 2000)\n",
        "    daily_conversions = random.randint(5, daily_clicks // 10)\n",
        "    revenue = daily_conversions * round(random.uniform(50, 500), 2)\n",
        "    roi = round((revenue - daily_spend) / daily_spend, 2)\n",
        "\n",
        "    forecasting_data.append({\n",
        "        \"Date\": date.strftime(\"%Y-%m-%d\"),\n",
        "        \"Campaign_ID\": campaign_id,\n",
        "        \"Daily_Spend ($)\": daily_spend,\n",
        "        \"Daily_Clicks\": daily_clicks,\n",
        "        \"Daily_Conversions\": daily_conversions,\n",
        "        \"Daily_Revenue ($)\": revenue,\n",
        "        \"Daily_ROI\": roi\n",
        "    })\n",
        "    date += timedelta(days=1)\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "forecast_df = pd.DataFrame(forecasting_data)\n",
        "forecast_df.to_csv(\"Campaign_Forecasting.csv\", index=False)\n",
        "print(\"Campaign Forecasting Data Saved!\")\n"
      ],
      "metadata": {
        "id": "Ac921I0Vjdj9",
        "outputId": "b9ca0674-4d92-463f-8821-081972cfb98f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marketing Campaign Data Saved!\n",
            "Customer Response Data Saved!\n",
            "Campaign Forecasting Data Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Generated CSV Files**\n",
        "1. **Marketing_Campaigns.csv** â†’ **Campaign details**, budget, impressions, CPA, ROI  \n",
        "2. **Customer_Responses.csv** â†’ **Customer demographics**, segmentation, engagement, LTV  \n",
        "3. **Campaign_Forecasting.csv** â†’ **Daily campaign spending, conversions, ROI predictions**  \n",
        "\n",
        "ðŸš€ **Excel-Ready for Pivot Tables, ROI Optimization & Forecasting!**  \n",
        "Let me know if you need **modifications or additional data points!** ðŸ˜Š"
      ],
      "metadata": {
        "id": "YtcTP_YqkRJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Customer Analytics & Churn Prediction Data**  \n",
        "This script generates structured **customer analytics data** for the **Customer Analytics & Churn Prediction System** project. It follows logical data relationships rather than using purely random values.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Synthetic Data**  \n",
        "âœ… **Customer Data (5,000 customers, 2 years of transactions)**  \n",
        "âœ… **Purchase Behavior (Frequency, Recency, and Monetary analysis - RFM)**  \n",
        "âœ… **Churn Indicators (Inactive periods, engagement score, discount usage, complaints)**  \n",
        "âœ… **Customer Segmentation (New, Loyal, At-Risk, Churned)**  \n",
        "âœ… **Churn Prediction Features (Logistic Regression-ready data)**  \n",
        "âœ… **Lifetime Value (CLV) Calculation using financial formulas**  \n",
        "âœ… **Cohort Analysis (Customer retention trends over time)**  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python"
      ],
      "metadata": {
        "id": "wO4QV8MXlifl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define parameters\n",
        "num_customers = 5000\n",
        "start_date = datetime(2022, 1, 1)\n",
        "end_date = datetime(2024, 1, 1)\n",
        "segments = [\"New\", \"Loyal\", \"At-Risk\", \"Churned\"]\n",
        "industries = [\"Retail\", \"Finance\", \"Healthcare\", \"Technology\", \"Automotive\"]\n",
        "acquisition_channels = [\"Social Media\", \"Referral\", \"Google Ads\", \"Email\", \"Direct\"]\n",
        "engagement_scores = [0, 1, 2, 3, 4, 5]  # 0: Low, 5: High\n",
        "\n",
        "# Generate Customer Profile Data\n",
        "customers = []\n",
        "for i in range(1, num_customers + 1):\n",
        "    customer_id = f\"C{i:04}\"\n",
        "    age = random.randint(18, 65)\n",
        "    gender = random.choice([\"Male\", \"Female\", \"Other\"])\n",
        "    industry = random.choice(industries)\n",
        "    signup_date = start_date + timedelta(days=random.randint(0, 730))  # Customer signed up within 2 years\n",
        "    acquisition_channel = random.choice(acquisition_channels)\n",
        "    engagement_score = random.choice(engagement_scores)\n",
        "    segment = \"New\" if (datetime(2024, 1, 1) - signup_date).days < 90 else random.choice(segments)\n",
        "\n",
        "    customers.append({\n",
        "        \"Customer_ID\": customer_id,\n",
        "        \"Age\": age,\n",
        "        \"Gender\": gender,\n",
        "        \"Industry\": industry,\n",
        "        \"Signup_Date\": signup_date.strftime(\"%Y-%m-%d\"),\n",
        "        \"Acquisition_Channel\": acquisition_channel,\n",
        "        \"Engagement_Score\": engagement_score,\n",
        "        \"Segment\": segment\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "customers_df = pd.DataFrame(customers)\n",
        "customers_df.to_csv(\"Customer_Profiles.csv\", index=False)\n",
        "print(\"Customer Profile Data Saved!\")\n",
        "\n",
        "# Generate Transaction Data for 2 years\n",
        "transactions = []\n",
        "for customer in customers:\n",
        "    customer_id = customer[\"Customer_ID\"]\n",
        "    num_transactions = random.randint(1, 50) if customer[\"Segment\"] != \"Churned\" else random.randint(0, 10)\n",
        "\n",
        "    for _ in range(num_transactions):\n",
        "        transaction_date = customer[\"Signup_Date\"]  # Start from signup date\n",
        "        transaction_date = datetime.strptime(transaction_date, \"%Y-%m-%d\") + timedelta(days=random.randint(1, 700))\n",
        "        if transaction_date > end_date:\n",
        "            continue\n",
        "\n",
        "        amount_spent = round(random.uniform(10, 500), 2)  # Purchase amount\n",
        "        discount_used = random.choice([0, 1]) if amount_spent > 100 else 0  # Discount usage\n",
        "        complaints = random.choice([0, 1]) if random.random() < 0.05 else 0  # Complaint occurrence (5% chance)\n",
        "\n",
        "        transactions.append({\n",
        "            \"Customer_ID\": customer_id,\n",
        "            \"Transaction_Date\": transaction_date.strftime(\"%Y-%m-%d\"),\n",
        "            \"Amount_Spent ($)\": amount_spent,\n",
        "            \"Discount_Used\": discount_used,\n",
        "            \"Complaints\": complaints\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "transactions_df = pd.DataFrame(transactions)\n",
        "transactions_df.to_csv(\"Customer_Transactions.csv\", index=False)\n",
        "print(\"Transaction Data Saved!\")\n",
        "\n",
        "# Generate RFM Metrics\n",
        "rfm_data = []\n",
        "for customer in customers:\n",
        "    customer_id = customer[\"Customer_ID\"]\n",
        "    customer_transactions = transactions_df[transactions_df[\"Customer_ID\"] == customer_id]\n",
        "\n",
        "    if customer_transactions.empty:\n",
        "        recency = 730  # If no transactions, assume the worst case (2 years without purchase)\n",
        "        frequency = 0\n",
        "        monetary = 0\n",
        "    else:\n",
        "        last_purchase_date = max(pd.to_datetime(customer_transactions[\"Transaction_Date\"]))\n",
        "        recency = (datetime(2024, 1, 1) - last_purchase_date).days\n",
        "        frequency = len(customer_transactions)\n",
        "        monetary = customer_transactions[\"Amount_Spent ($)\"].sum()\n",
        "\n",
        "    rfm_data.append({\n",
        "        \"Customer_ID\": customer_id,\n",
        "        \"Recency (Days)\": recency,\n",
        "        \"Frequency\": frequency,\n",
        "        \"Monetary ($)\": monetary\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "rfm_df = pd.DataFrame(rfm_data)\n",
        "rfm_df.to_csv(\"RFM_Analysis.csv\", index=False)\n",
        "print(\"RFM Analysis Data Saved!\")\n",
        "\n",
        "# Generate Churn Prediction Data\n",
        "churn_prediction_data = []\n",
        "for customer in customers:\n",
        "    customer_id = customer[\"Customer_ID\"]\n",
        "    rfm = rfm_df[rfm_df[\"Customer_ID\"] == customer_id].iloc[0]\n",
        "\n",
        "    churn_probability = round(1 / (1 + np.exp(-(0.02 * rfm[\"Recency (Days)\"] - 0.05 * rfm[\"Frequency\"] + 0.001 * rfm[\"Monetary ($)\"]))), 2)\n",
        "    churned = 1 if churn_probability > 0.7 else 0  # If churn probability > 70%, mark as churned\n",
        "\n",
        "    churn_prediction_data.append({\n",
        "        \"Customer_ID\": customer_id,\n",
        "        \"Recency (Days)\": rfm[\"Recency (Days)\"],\n",
        "        \"Frequency\": rfm[\"Frequency\"],\n",
        "        \"Monetary ($)\": rfm[\"Monetary ($)\"],\n",
        "        \"Churn_Probability\": churn_probability,\n",
        "        \"Churned\": churned\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "churn_df = pd.DataFrame(churn_prediction_data)\n",
        "churn_df.to_csv(\"Churn_Prediction.csv\", index=False)\n",
        "print(\"Churn Prediction Data Saved!\")\n",
        "\n",
        "# Generate Customer Lifetime Value (CLV)\n",
        "clv_data = []\n",
        "for customer in customers:\n",
        "    customer_id = customer[\"Customer_ID\"]\n",
        "    rfm = rfm_df[rfm_df[\"Customer_ID\"] == customer_id].iloc[0]\n",
        "\n",
        "    avg_purchase_value = rfm[\"Monetary ($)\"] / max(rfm[\"Frequency\"], 1)\n",
        "    purchase_frequency = rfm[\"Frequency\"] / 24  # Monthly frequency assumption\n",
        "    churn_rate = churn_df[churn_df[\"Customer_ID\"] == customer_id][\"Churn_Probability\"].iloc[0]\n",
        "\n",
        "    if churn_rate == 1:  # If customer is certain to churn, CLV is 0\n",
        "        clv = 0\n",
        "    else:\n",
        "        clv = round((avg_purchase_value * purchase_frequency) / churn_rate, 2)\n",
        "\n",
        "    clv_data.append({\n",
        "        \"Customer_ID\": customer_id,\n",
        "        \"Average_Purchase_Value ($)\": avg_purchase_value,\n",
        "        \"Purchase_Frequency\": purchase_frequency,\n",
        "        \"Churn_Rate\": churn_rate,\n",
        "        \"CLV ($)\": clv\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame & Save\n",
        "clv_df = pd.DataFrame(clv_data)\n",
        "clv_df.to_csv(\"Customer_Lifetime_Value.csv\", index=False)\n",
        "print(\"Customer Lifetime Value Data Saved!\")\n"
      ],
      "metadata": {
        "id": "4mqSXRYakRiK",
        "outputId": "185a8028-5e2c-4efe-ff42-937073bb5ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Profile Data Saved!\n",
            "Transaction Data Saved!\n",
            "RFM Analysis Data Saved!\n",
            "Churn Prediction Data Saved!\n",
            "Customer Lifetime Value Data Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Generated CSV Files**\n",
        "1. **Customer_Profiles.csv** â†’ Age, Gender, Industry, Engagement Score, Acquisition Channel  \n",
        "2. **Customer_Transactions.csv** â†’ Purchase history, Amount Spent, Discounts, Complaints  \n",
        "3. **RFM_Analysis.csv** â†’ Recency, Frequency, and Monetary values  \n",
        "4. **Churn_Prediction.csv** â†’ Churn probability and status  \n",
        "5. **Customer_Lifetime_Value.csv** â†’ CLV calculations based on financial formulas  \n",
        "\n",
        "ðŸš€ **Ready for Churn Prediction, Customer Segmentation, and Retention Analysis!**  \n",
        "Let me know if you need any **modifications or extra features**. ðŸ˜Š"
      ],
      "metadata": {
        "id": "EfjJfioVlnfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hereâ€™s a Python script to generate synthetic data for both projects. The script follows the logic described in the project plans, ensuring meaningful data rather than random values. It generates:  \n",
        "\n",
        "1. **Customer Analytics & Churn Prediction Data**  \n",
        "   - Customer transactions over two years (5000+ customers)  \n",
        "   - Customer segmentation using RFM (Recency, Frequency, Monetary)  \n",
        "   - Churn risk based on transaction history  \n",
        "\n",
        "2. **Financial Statement Data for Analysis & Forecasting**  \n",
        "   - Standardized financial statements for multiple years  \n",
        "   - Financial ratios (liquidity, profitability, efficiency, solvency)  \n",
        "   - Trend analysis and projections  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script for Synthetic Data Generation**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "hYUrHKNpm6C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Generate Synthetic Customer Data\n",
        "def generate_customer_data(num_customers=5000, num_transactions=20000):\n",
        "    customer_ids = [f\"CUST_{i}\" for i in range(1, num_customers + 1)]\n",
        "    transaction_dates = [datetime(2022, 1, 1) + timedelta(days=random.randint(0, 730)) for _ in range(num_transactions)]\n",
        "\n",
        "    transaction_data = pd.DataFrame({\n",
        "        \"CustomerID\": np.random.choice(customer_ids, num_transactions),\n",
        "        \"TransactionDate\": transaction_dates,\n",
        "        \"Amount\": np.round(np.random.uniform(10, 1000, num_transactions), 2)\n",
        "    })\n",
        "\n",
        "    # Calculate RFM Metrics\n",
        "    latest_date = max(transaction_data[\"TransactionDate\"])\n",
        "    rfm_data = transaction_data.groupby(\"CustomerID\").agg(\n",
        "        Recency=(\"TransactionDate\", lambda x: (latest_date - x.max()).days),\n",
        "        Frequency=(\"CustomerID\", \"count\"),\n",
        "        Monetary=(\"Amount\", \"sum\")\n",
        "    ).reset_index()\n",
        "\n",
        "    # Define churn risk: Customers with high recency and low frequency are at risk\n",
        "    rfm_data[\"ChurnRisk\"] = np.where((rfm_data[\"Recency\"] > 180) & (rfm_data[\"Frequency\"] < 5), \"High\",\n",
        "                                     np.where((rfm_data[\"Recency\"] > 90), \"Medium\", \"Low\"))\n",
        "\n",
        "    return transaction_data, rfm_data\n",
        "\n",
        "# 2. Generate Synthetic Financial Statement Data\n",
        "def generate_financial_data(years=5):\n",
        "    years_range = list(range(2019, 2019 + years))\n",
        "\n",
        "    financial_data = pd.DataFrame({\n",
        "        \"Year\": np.repeat(years_range, 1),\n",
        "        \"Revenue\": np.round(np.random.uniform(500000, 2000000, years), 2),\n",
        "        \"COGS\": np.round(np.random.uniform(200000, 1000000, years), 2),\n",
        "        \"Operating_Expenses\": np.round(np.random.uniform(50000, 300000, years), 2),\n",
        "        \"Net_Income\": np.round(np.random.uniform(100000, 800000, years), 2),\n",
        "        \"Total_Assets\": np.round(np.random.uniform(500000, 3000000, years), 2),\n",
        "        \"Total_Liabilities\": np.round(np.random.uniform(200000, 1500000, years), 2),\n",
        "        \"Equity\": np.round(np.random.uniform(300000, 2500000, years), 2)\n",
        "    })\n",
        "\n",
        "    # Calculate Financial Ratios\n",
        "    financial_data[\"Current_Ratio\"] = (financial_data[\"Total_Assets\"] / financial_data[\"Total_Liabilities\"]).round(2)\n",
        "    financial_data[\"ROE\"] = (financial_data[\"Net_Income\"] / financial_data[\"Equity\"]).round(2)\n",
        "    financial_data[\"Debt_to_Equity\"] = (financial_data[\"Total_Liabilities\"] / financial_data[\"Equity\"]).round(2)\n",
        "    financial_data[\"Net_Profit_Margin\"] = (financial_data[\"Net_Income\"] / financial_data[\"Revenue\"]).round(2)\n",
        "\n",
        "    return financial_data\n",
        "\n",
        "# Generate Data\n",
        "transactions, customer_segments = generate_customer_data()\n",
        "financials = generate_financial_data()\n",
        "\n",
        "# Save to CSV\n",
        "transactions.to_csv(\"synthetic_transactions.csv\", index=False)\n",
        "customer_segments.to_csv(\"synthetic_customer_segments.csv\", index=False)\n",
        "financials.to_csv(\"synthetic_financial_statements.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic data generated and saved successfully!\")"
      ],
      "metadata": {
        "id": "m28CVqRKlmb5",
        "outputId": "b4d0ce91-2973-43ee-ce21-7d0eb9bf1e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data generated and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Output Files**\n",
        "1. `synthetic_transactions.csv`: Contains customer transactions with date, amount, and customer ID.  \n",
        "2. `synthetic_customer_segments.csv`: Includes **RFM scores** and churn risk levels for each customer.  \n",
        "3. `synthetic_financial_statements.csv`: Provides financial statements with calculated ratios.  \n",
        "\n",
        "Let me know if you need modifications or additional metrics! ðŸš€"
      ],
      "metadata": {
        "id": "YXObCRtGnAmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Synthetic Operations Analytics & Process Optimization Data**  \n",
        "\n",
        "This script generates synthetic data based on the logical requirements from **Project 8**. It includes:  \n",
        "1. **Operations Data** â€“ Simulating production, quality, and resource utilization records.  \n",
        "2. **Process Performance Analysis** â€“ Calculating key metrics like **Overall Equipment Effectiveness (OEE)**.  \n",
        "3. **Quality Control Metrics** â€“ Generating **defect rates** and **Statistical Process Control (SPC) data**.  \n",
        "4. **Production Forecasting Data** â€“ Time-series based synthetic production volume.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python"
      ],
      "metadata": {
        "id": "e5oaRh2inVMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Generate Synthetic Operations Data\n",
        "def generate_operations_data(num_records=10000):\n",
        "    process_stages = [\"Raw Material Prep\", \"Manufacturing\", \"Assembly\", \"Quality Check\", \"Packaging\"]\n",
        "    machine_ids = [f\"MCH_{i}\" for i in range(1, 21)]\n",
        "    start_date = datetime(2022, 1, 1)\n",
        "\n",
        "    data = []\n",
        "    for _ in range(num_records):\n",
        "        process = random.choice(process_stages)\n",
        "        date = start_date + timedelta(days=random.randint(0, 730))\n",
        "        cycle_time = round(np.random.normal(30, 10), 2)  # Avg cycle time 30 mins\n",
        "        defect_rate = round(np.random.uniform(0, 0.1), 4)  # Defect rate between 0% and 10%\n",
        "        machine = random.choice(machine_ids)\n",
        "        downtime = round(np.random.uniform(0, 5), 2)  # Downtime in hours\n",
        "\n",
        "        data.append([date, process, machine, cycle_time, defect_rate, downtime])\n",
        "\n",
        "    operations_df = pd.DataFrame(data, columns=[\"Date\", \"Process_Stage\", \"Machine_ID\", \"Cycle_Time\", \"Defect_Rate\", \"Downtime\"])\n",
        "    return operations_df\n",
        "\n",
        "# 2. Calculate Process Performance Metrics\n",
        "def calculate_oee(data):\n",
        "    grouped = data.groupby(\"Machine_ID\").agg(\n",
        "        Availability=(\"Downtime\", lambda x: 1 - (x.mean() / 8)),  # Assuming an 8-hour shift\n",
        "        Performance=(\"Cycle_Time\", lambda x: 1 - (x.mean() / 40)),  # Ideal cycle time is 40 mins\n",
        "        Quality=(\"Defect_Rate\", lambda x: 1 - x.mean())  # Quality factor\n",
        "    ).reset_index()\n",
        "\n",
        "    grouped[\"OEE\"] = (grouped[\"Availability\"] * grouped[\"Performance\"] * grouped[\"Quality\"]).round(2)\n",
        "    return grouped\n",
        "\n",
        "# 3. Generate Synthetic Quality Control Data\n",
        "def generate_quality_control_data(num_records=500):\n",
        "    defect_types = [\"Scratches\", \"Misalignment\", \"Color Mismatch\", \"Incorrect Assembly\", \"Cracks\"]\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_records):\n",
        "        date = datetime(2022, 1, 1) + timedelta(days=random.randint(0, 730))\n",
        "        defect_type = random.choice(defect_types)\n",
        "        defect_count = random.randint(1, 50)\n",
        "\n",
        "        data.append([date, defect_type, defect_count])\n",
        "\n",
        "    quality_df = pd.DataFrame(data, columns=[\"Date\", \"Defect_Type\", \"Defect_Count\"])\n",
        "    return quality_df\n",
        "\n",
        "# 4. Generate Production Forecasting Data\n",
        "def generate_production_forecast(years=3):\n",
        "    start_year = 2022\n",
        "    months = [f\"{start_year + i}-{m:02d}\" for i in range(years) for m in range(1, 13)]\n",
        "\n",
        "    forecast_data = pd.DataFrame({\n",
        "        \"Month\": months,\n",
        "        \"Production_Units\": np.round(np.random.uniform(500, 5000, len(months)), 0)\n",
        "    })\n",
        "\n",
        "    return forecast_data\n",
        "\n",
        "# Generate Data\n",
        "operations_df = generate_operations_data()\n",
        "oee_df = calculate_oee(operations_df)\n",
        "quality_df = generate_quality_control_data()\n",
        "forecast_df = generate_production_forecast()\n",
        "\n",
        "# Save to CSV\n",
        "operations_df.to_csv(\"synthetic_operations_data.csv\", index=False)\n",
        "oee_df.to_csv(\"synthetic_oee_metrics.csv\", index=False)\n",
        "quality_df.to_csv(\"synthetic_quality_control.csv\", index=False)\n",
        "forecast_df.to_csv(\"synthetic_production_forecast.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic data generated and saved successfully!\")"
      ],
      "metadata": {
        "id": "HPghVq7Cm_vp",
        "outputId": "450130b2-76c1-4e44-e3bd-8ffc3a006eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data generated and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Output Files**\n",
        "1. **`synthetic_operations_data.csv`** â€“ Tracks production processes, cycle times, defect rates, and downtime.  \n",
        "2. **`synthetic_oee_metrics.csv`** â€“ Calculates **Overall Equipment Effectiveness (OEE)** for each machine.  \n",
        "3. **`synthetic_quality_control.csv`** â€“ Contains defect analysis for different product defects over time.  \n",
        "4. **`synthetic_production_forecast.csv`** â€“ Provides synthetic production volume forecasts for multiple years.  \n",
        "\n",
        "Would you like any additional features or modifications? ðŸš€"
      ],
      "metadata": {
        "id": "rMfqQqvvne5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Synthetic Financial Portfolio Analysis Data**  \n",
        "\n",
        "This script generates **synthetic financial portfolio data**, including:  \n",
        "1. **Stock Prices** â€“ Simulating stock market data for multiple assets over time.  \n",
        "2. **Portfolio Holdings** â€“ Sample asset allocations across various investments.  \n",
        "3. **Risk & Return Metrics** â€“ Volatility, Sharpe ratios, and risk-adjusted returns.  \n",
        "4. **Forecasting Data** â€“ Simulated return projections using statistical models.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python\n"
      ],
      "metadata": {
        "id": "Ibj3qGLxoPyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Generate Synthetic Stock Price Data\n",
        "def generate_stock_data(start_date=\"2020-01-01\", end_date=\"2024-12-31\", num_assets=10):\n",
        "    dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
        "    asset_names = [f\"Asset_{i}\" for i in range(1, num_assets+1)]\n",
        "\n",
        "    data = { \"Date\": dates }\n",
        "    for asset in asset_names:\n",
        "        prices = np.cumsum(np.random.randn(len(dates)) * 2 + 0.5) + 100  # Simulating random stock price changes\n",
        "        data[asset] = np.round(prices, 2)\n",
        "\n",
        "    stock_df = pd.DataFrame(data)\n",
        "    return stock_df\n",
        "\n",
        "# 2. Generate Portfolio Holdings Data\n",
        "def generate_portfolio_data(num_holdings=20):\n",
        "    asset_names = [f\"Asset_{i}\" for i in range(1, 11)]\n",
        "    sectors = [\"Tech\", \"Healthcare\", \"Finance\", \"Energy\", \"Consumer Goods\"]\n",
        "\n",
        "    data = []\n",
        "    for _ in range(num_holdings):\n",
        "        asset = random.choice(asset_names)\n",
        "        sector = random.choice(sectors)\n",
        "        weight = round(np.random.uniform(0.01, 0.2), 3)  # Portfolio allocation %\n",
        "        return_annual = round(np.random.uniform(-10, 30), 2)  # Simulated annual return %\n",
        "        volatility = round(np.random.uniform(5, 25), 2)  # Risk (standard deviation)\n",
        "\n",
        "        data.append([asset, sector, weight, return_annual, volatility])\n",
        "\n",
        "    portfolio_df = pd.DataFrame(data, columns=[\"Asset\", \"Sector\", \"Weight\", \"Annual_Return\", \"Volatility\"])\n",
        "    return portfolio_df\n",
        "\n",
        "# 3. Generate Risk & Return Metrics\n",
        "def calculate_risk_metrics(portfolio_df):\n",
        "    portfolio_df[\"Sharpe_Ratio\"] = (portfolio_df[\"Annual_Return\"] - 2) / portfolio_df[\"Volatility\"]  # Assuming risk-free rate = 2%\n",
        "    portfolio_df[\"Risk_Adjusted_Return\"] = portfolio_df[\"Annual_Return\"] / portfolio_df[\"Volatility\"]\n",
        "    return portfolio_df\n",
        "\n",
        "# 4. Generate Forecasting Data\n",
        "def generate_return_forecast(num_months=24):\n",
        "    months = pd.date_range(start=\"2024-01-01\", periods=num_months, freq=\"ME\")\n",
        "    forecast_data = pd.DataFrame({\n",
        "        \"Month\": months,\n",
        "        \"Projected_Return\": np.round(np.random.uniform(-5, 10, num_months), 2)  # Simulated returns\n",
        "    })\n",
        "    return forecast_data\n",
        "\n",
        "# Generate Data\n",
        "stock_df = generate_stock_data()\n",
        "portfolio_df = generate_portfolio_data()\n",
        "portfolio_df = calculate_risk_metrics(portfolio_df)\n",
        "forecast_df = generate_return_forecast()\n",
        "\n",
        "# Save to CSV\n",
        "stock_df.to_csv(\"synthetic_stock_prices.csv\", index=False)\n",
        "portfolio_df.to_csv(\"synthetic_portfolio_holdings.csv\", index=False)\n",
        "forecast_df.to_csv(\"synthetic_return_forecast.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic financial data generated and saved successfully!\")\n"
      ],
      "metadata": {
        "id": "4ysZ8MzGneHA",
        "outputId": "a94495b2-0970-4eee-a0ee-1eb65cc9666b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic financial data generated and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Generated Output Files**\n",
        "1. **`synthetic_stock_prices.csv`** â€“ Simulated daily stock prices for multiple assets.  \n",
        "2. **`synthetic_portfolio_holdings.csv`** â€“ Portfolio composition, risk-return metrics, and sector allocations.  \n",
        "3. **`synthetic_return_forecast.csv`** â€“ Simulated monthly return forecasts for financial planning.  \n",
        "\n",
        "Would you like additional features, such as Monte Carlo simulations or correlation analysis? ðŸš€"
      ],
      "metadata": {
        "id": "EpJFKWYFoVkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Synthetic HR Analytics & Workforce Planning Data**  \n",
        "\n",
        "This script generates **synthetic HR data** for workforce analytics, including:  \n",
        "1. **Employee Records** â€“ Simulated employee demographics, job roles, and salaries.  \n",
        "2. **Performance & Attrition Data** â€“ Performance scores, promotion history, and attrition risk.  \n",
        "3. **Workforce Forecasting** â€“ Predictive insights for employee turnover and hiring needs.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python\n"
      ],
      "metadata": {
        "id": "z-k9pCq8pfuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1. Generate Synthetic Employee Data\n",
        "def generate_employee_data(num_employees=500):\n",
        "    departments = [\"HR\", \"Finance\", \"IT\", \"Marketing\", \"Operations\", \"Sales\"]\n",
        "    job_roles = {\n",
        "        \"HR\": [\"HR Manager\", \"HR Specialist\", \"Recruiter\"],\n",
        "        \"Finance\": [\"Financial Analyst\", \"Accountant\", \"Treasury Manager\"],\n",
        "        \"IT\": [\"Software Engineer\", \"Data Scientist\", \"IT Support\"],\n",
        "        \"Marketing\": [\"Marketing Manager\", \"SEO Specialist\", \"Content Strategist\"],\n",
        "        \"Operations\": [\"Operations Manager\", \"Logistics Coordinator\", \"Supply Chain Analyst\"],\n",
        "        \"Sales\": [\"Sales Executive\", \"Business Development Manager\", \"Account Manager\"]\n",
        "    }\n",
        "\n",
        "    data = []\n",
        "    for i in range(1, num_employees + 1):\n",
        "        emp_id = f\"EMP{i:04d}\"\n",
        "        department = random.choice(departments)\n",
        "        job_title = random.choice(job_roles[department])\n",
        "        hire_date = datetime(2015, 1, 1) + timedelta(days=random.randint(0, 365 * 9))  # Between 2015 and 2024\n",
        "        tenure = round((datetime(2024, 1, 1) - hire_date).days / 365, 1)\n",
        "        age = random.randint(22, 60)\n",
        "        salary = round(random.uniform(30000, 150000), 2)\n",
        "        performance_score = round(random.uniform(1, 5), 1)  # Rating between 1 and 5\n",
        "        promotions = random.randint(0, 3)\n",
        "        attrition_risk = round(np.random.uniform(0, 1), 2)  # Probability of leaving\n",
        "\n",
        "        data.append([emp_id, department, job_title, hire_date.strftime(\"%Y-%m-%d\"), tenure, age, salary,\n",
        "                     performance_score, promotions, attrition_risk])\n",
        "\n",
        "    employee_df = pd.DataFrame(data, columns=[\"Employee_ID\", \"Department\", \"Job_Title\", \"Hire_Date\", \"Tenure\",\n",
        "                                              \"Age\", \"Salary\", \"Performance_Score\", \"Promotions\", \"Attrition_Risk\"])\n",
        "    return employee_df\n",
        "\n",
        "# 2. Generate Attrition Forecast Data\n",
        "def generate_attrition_forecast(num_months=24):\n",
        "    months = pd.date_range(start=\"2024-01-01\", periods=num_months, freq=\"ME\")\n",
        "    forecast_data = pd.DataFrame({\n",
        "        \"Month\": months,\n",
        "        \"Projected_Attrition\": np.round(np.random.uniform(0, 20, num_months), 2)  # Monthly attrition forecast\n",
        "    })\n",
        "    return forecast_data\n",
        "\n",
        "# Generate Data\n",
        "employee_df = generate_employee_data()\n",
        "forecast_df = generate_attrition_forecast()\n",
        "\n",
        "# Save to CSV\n",
        "employee_df.to_csv(\"synthetic_employee_data.csv\", index=False)\n",
        "forecast_df.to_csv(\"synthetic_attrition_forecast.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic HR data generated and saved successfully!\")\n"
      ],
      "metadata": {
        "id": "xnhK2zzPoWit",
        "outputId": "b31a956b-5574-4971-e674-08ef09b414b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic HR data generated and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Output Files**\n",
        "1. **`synthetic_employee_data.csv`** â€“ Simulated employee records, including tenure, salary, performance, and attrition risk.  \n",
        "2. **`synthetic_attrition_forecast.csv`** â€“ Monthly projections for employee turnover.  \n",
        "\n",
        "Would you like additional features, such as **workforce diversity analysis or salary trend forecasting**? ðŸš€"
      ],
      "metadata": {
        "id": "VvUT03mLpmyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Logical Supply Chain & Inventory Data Generation**  \n",
        "\n",
        "This script generates **structured supply chain data** using logical rules instead of purely random values. It includes:  \n",
        "\n",
        "1. **Product Inventory Data** â€“ Categorized stock levels, reorder points, and supplier info.  \n",
        "2. **Order History Data** â€“ Past customer orders with logical demand trends.  \n",
        "3. **Supplier Performance Data** â€“ Lead times, reliability scores, and historical order fulfillment.  \n",
        "4. **Inventory Forecasting Module** â€“ Demand projection and reorder scheduling based on sales trends.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python\n"
      ],
      "metadata": {
        "id": "_fzM-8_1qP4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Product Categories and Suppliers\n",
        "categories = {\n",
        "    \"Electronics\": [\"Laptop\", \"Smartphone\", \"Tablet\", \"Smartwatch\"],\n",
        "    \"Clothing\": [\"Jeans\", \"T-Shirt\", \"Jacket\", \"Sneakers\"],\n",
        "    \"Groceries\": [\"Rice\", \"Milk\", \"Eggs\", \"Vegetables\"],\n",
        "    \"Furniture\": [\"Sofa\", \"Table\", \"Chair\", \"Bed\"]\n",
        "}\n",
        "\n",
        "suppliers = {\n",
        "    \"Electronics\": [\"TechSupply Ltd\", \"GadgetCo\", \"DigitalWorld\"],\n",
        "    \"Clothing\": [\"FashionMart\", \"TrendyWear\", \"StyleX\"],\n",
        "    \"Groceries\": [\"FreshFarm\", \"DailyGoods\", \"AgroFoods\"],\n",
        "    \"Furniture\": [\"HomeLiving\", \"FurniCraft\", \"WoodWorks\"]\n",
        "}\n",
        "\n",
        "# Generate Product Inventory\n",
        "def generate_inventory():\n",
        "    inventory_data = []\n",
        "    for category, products in categories.items():\n",
        "        for product in products:\n",
        "            supplier = np.random.choice(suppliers[category])\n",
        "            stock_level = np.random.randint(50, 500)  # Logical stock range\n",
        "            reorder_point = stock_level // 3  # Reorder when 1/3rd of stock is left\n",
        "            lead_time = np.random.randint(5, 15)  # Days required for resupply\n",
        "            demand_trend = np.random.randint(5, 50)  # Expected daily demand\n",
        "\n",
        "            inventory_data.append([product, category, supplier, stock_level, reorder_point, lead_time, demand_trend])\n",
        "\n",
        "    return pd.DataFrame(inventory_data, columns=[\n",
        "        \"Product\", \"Category\", \"Supplier\", \"Stock_Level\", \"Reorder_Point\", \"Lead_Time\", \"Daily_Demand\"\n",
        "    ])\n",
        "\n",
        "# Generate Order History with Logical Trends\n",
        "def generate_orders(num_orders=1000):\n",
        "    order_data = []\n",
        "    start_date = datetime(2023, 1, 1)\n",
        "\n",
        "    for _ in range(num_orders):\n",
        "        category = np.random.choice(list(categories.keys()))\n",
        "        product = np.random.choice(categories[category])\n",
        "        order_date = start_date + timedelta(days=np.random.randint(0, 365))  # Random past year order date\n",
        "        quantity = np.random.randint(1, 10)  # Customer orders between 1-10 units\n",
        "        price_per_unit = np.random.randint(10, 200)  # Logical price range\n",
        "        total_cost = quantity * price_per_unit\n",
        "\n",
        "        order_data.append([order_date.strftime(\"%Y-%m-%d\"), product, category, quantity, price_per_unit, total_cost])\n",
        "\n",
        "    return pd.DataFrame(order_data, columns=[\n",
        "        \"Order_Date\", \"Product\", \"Category\", \"Quantity\", \"Price_Per_Unit\", \"Total_Cost\"\n",
        "    ])\n",
        "\n",
        "# Generate Supplier Performance Data\n",
        "def generate_supplier_performance():\n",
        "    supplier_data = []\n",
        "    for category, supplier_list in suppliers.items():\n",
        "        for supplier in supplier_list:\n",
        "            avg_lead_time = np.random.randint(5, 15)\n",
        "            reliability = round(np.random.uniform(85, 99), 2)  # % of on-time deliveries\n",
        "            defect_rate = round(np.random.uniform(0.5, 5), 2)  # % of defective items\n",
        "\n",
        "            supplier_data.append([supplier, category, avg_lead_time, reliability, defect_rate])\n",
        "\n",
        "    return pd.DataFrame(supplier_data, columns=[\n",
        "        \"Supplier\", \"Category\", \"Avg_Lead_Time\", \"Reliability (%)\", \"Defect_Rate (%)\"\n",
        "    ])\n",
        "\n",
        "# Generate Forecasted Inventory Levels\n",
        "def generate_inventory_forecast(months=6):\n",
        "    forecast_data = []\n",
        "    today = datetime.today()\n",
        "\n",
        "    for i in range(months):\n",
        "        future_date = today + timedelta(days=30 * (i+1))\n",
        "        projected_stock = np.random.randint(50, 500)\n",
        "        reorder_needed = \"Yes\" if projected_stock < 100 else \"No\"\n",
        "\n",
        "        forecast_data.append([future_date.strftime(\"%Y-%m-%d\"), projected_stock, reorder_needed])\n",
        "\n",
        "    return pd.DataFrame(forecast_data, columns=[\"Forecast_Date\", \"Projected_Stock\", \"Reorder_Needed\"])\n",
        "\n",
        "# Generate DataFrames\n",
        "inventory_df = generate_inventory()\n",
        "orders_df = generate_orders()\n",
        "supplier_df = generate_supplier_performance()\n",
        "forecast_df = generate_inventory_forecast()\n",
        "\n",
        "# Save to CSV\n",
        "inventory_df.to_csv(\"synthetic_inventory_data.csv\", index=False)\n",
        "orders_df.to_csv(\"synthetic_orders_data.csv\", index=False)\n",
        "supplier_df.to_csv(\"synthetic_supplier_data.csv\", index=False)\n",
        "forecast_df.to_csv(\"synthetic_inventory_forecast.csv\", index=False)\n",
        "\n",
        "print(\"Supply chain dataset successfully generated and saved!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6yxxlEwplMn",
        "outputId": "51508107-a262-4d08-81c0-6c8e652f3b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supply chain dataset successfully generated and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**\n",
        "1. **`synthetic_inventory_data.csv`** â€“ Stock levels, reorder points, supplier details, and demand trends.  \n",
        "2. **`synthetic_orders_data.csv`** â€“ Past orders with realistic date-based trends and pricing.  \n",
        "3. **`synthetic_supplier_data.csv`** â€“ Supplier reliability, lead times, and defect rates.  \n",
        "4. **`synthetic_inventory_forecast.csv`** â€“ Inventory projections and reorder signals for the next 6 months.  \n",
        "\n",
        "This dataset logically structures supply chain data rather than using purely random values. Would you like **demand trend analysis or seasonal forecasting** added? ðŸ“Š"
      ],
      "metadata": {
        "id": "p_TX3aHTqVGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Logical Marketing Campaign Data Generation**  \n",
        "\n",
        "This script generates **structured marketing campaign data** with logical patterns instead of random values. It includes:  \n",
        "\n",
        "1. **Campaign Data** â€“ Marketing campaigns with budgets, target audiences, and response rates.  \n",
        "2. **Customer Interaction Data** â€“ Tracking customer engagement, conversions, and acquisition costs.  \n",
        "3. **Channel Performance Data** â€“ Performance metrics across social media, email, search ads, and TV ads.  \n",
        "4. **ROI Forecasting Module** â€“ Predicting future campaign success based on response trends.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python"
      ],
      "metadata": {
        "id": "VI46wCx1tETy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Marketing Channels and Campaign Types\n",
        "channels = [\"Social Media\", \"Email\", \"Search Ads\", \"TV Ads\", \"Billboards\", \"Influencer Marketing\"]\n",
        "campaign_types = [\"Brand Awareness\", \"Lead Generation\", \"Product Launch\", \"Customer Retention\"]\n",
        "regions = [\"North America\", \"Europe\", \"Asia\", \"Australia\", \"South America\"]\n",
        "\n",
        "# Generate Campaign Data\n",
        "def generate_campaigns(num_campaigns=100):\n",
        "    campaign_data = []\n",
        "\n",
        "    for i in range(1, num_campaigns + 1):\n",
        "        campaign_name = f\"Campaign_{i}\"\n",
        "        campaign_type = np.random.choice(campaign_types)\n",
        "        channel = np.random.choice(channels)\n",
        "        region = np.random.choice(regions)\n",
        "        start_date = datetime(2023, 1, 1) + timedelta(days=np.random.randint(0, 365))\n",
        "        duration = np.random.randint(7, 90)  # Campaign runs between 1 week to 3 months\n",
        "        budget = np.random.randint(5000, 50000)  # Budget range in USD\n",
        "        expected_roi = round(np.random.uniform(1.2, 3.5), 2)  # ROI multiplier\n",
        "\n",
        "        campaign_data.append([campaign_name, campaign_type, channel, region, start_date.strftime(\"%Y-%m-%d\"),\n",
        "                              duration, budget, expected_roi])\n",
        "\n",
        "    return pd.DataFrame(campaign_data, columns=[\n",
        "        \"Campaign_Name\", \"Campaign_Type\", \"Channel\", \"Region\", \"Start_Date\", \"Duration_Days\", \"Budget\", \"Expected_ROI\"\n",
        "    ])\n",
        "\n",
        "# Generate Customer Engagement Data\n",
        "def generate_customer_interactions(num_records=1000):\n",
        "    interaction_data = []\n",
        "\n",
        "    for _ in range(num_records):\n",
        "        campaign_name = f\"Campaign_{np.random.randint(1, 101)}\"\n",
        "        customer_id = f\"CUST{np.random.randint(1000, 9999)}\"\n",
        "        channel = np.random.choice(channels)\n",
        "        engagement_type = np.random.choice([\"Click\", \"Signup\", \"Purchase\", \"Bounce\"])\n",
        "        engagement_date = datetime(2023, 1, 1) + timedelta(days=np.random.randint(0, 365))\n",
        "        cost_per_acquisition = round(np.random.uniform(5, 100), 2) if engagement_type == \"Purchase\" else 0\n",
        "\n",
        "        interaction_data.append([campaign_name, customer_id, channel, engagement_type, engagement_date.strftime(\"%Y-%m-%d\"), cost_per_acquisition])\n",
        "\n",
        "    return pd.DataFrame(interaction_data, columns=[\n",
        "        \"Campaign_Name\", \"Customer_ID\", \"Channel\", \"Engagement_Type\", \"Engagement_Date\", \"Cost_Per_Acquisition\"\n",
        "    ])\n",
        "\n",
        "# Generate Channel Performance Data\n",
        "def generate_channel_performance():\n",
        "    channel_data = []\n",
        "\n",
        "    for channel in channels:\n",
        "        avg_conversion_rate = round(np.random.uniform(0.5, 5), 2)  # % of users who convert\n",
        "        avg_cost_per_click = round(np.random.uniform(0.1, 5), 2)  # CPC for digital ads\n",
        "        reach = np.random.randint(10000, 500000)  # Estimated audience reach\n",
        "\n",
        "        channel_data.append([channel, avg_conversion_rate, avg_cost_per_click, reach])\n",
        "\n",
        "    return pd.DataFrame(channel_data, columns=[\n",
        "        \"Channel\", \"Avg_Conversion_Rate (%)\", \"Avg_Cost_Per_Click ($)\", \"Audience_Reach\"\n",
        "    ])\n",
        "\n",
        "# Generate ROI Forecast Data\n",
        "def generate_roi_forecast(months=6):\n",
        "    forecast_data = []\n",
        "    today = datetime.today()\n",
        "\n",
        "    for i in range(months):\n",
        "        future_date = today + timedelta(days=30 * (i+1))\n",
        "        projected_roi = round(np.random.uniform(1.2, 4.0), 2)\n",
        "        marketing_budget = np.random.randint(10000, 50000)\n",
        "\n",
        "        forecast_data.append([future_date.strftime(\"%Y-%m-%d\"), marketing_budget, projected_roi])\n",
        "\n",
        "    return pd.DataFrame(forecast_data, columns=[\"Forecast_Date\", \"Marketing_Budget\", \"Projected_ROI\"])\n",
        "\n",
        "# Generate DataFrames\n",
        "campaigns_df = generate_campaigns()\n",
        "interactions_df = generate_customer_interactions()\n",
        "channel_performance_df = generate_channel_performance()\n",
        "roi_forecast_df = generate_roi_forecast()\n",
        "\n",
        "# Save to CSV\n",
        "campaigns_df.to_csv(\"synthetic_campaign_data.csv\", index=False)\n",
        "interactions_df.to_csv(\"synthetic_customer_interactions.csv\", index=False)\n",
        "channel_performance_df.to_csv(\"synthetic_channel_performance.csv\", index=False)\n",
        "roi_forecast_df.to_csv(\"synthetic_roi_forecast.csv\", index=False)\n",
        "\n",
        "print(\"Marketing campaign dataset successfully generated and saved!\")"
      ],
      "metadata": {
        "id": "wwDDdqPpqUiO",
        "outputId": "59ba41d1-e557-42a3-cabb-ac84348ce941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marketing campaign dataset successfully generated and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**\n",
        "1. **`synthetic_campaign_data.csv`** â€“ Campaign details with budgets, ROI, regions, and marketing channels.  \n",
        "2. **`synthetic_customer_interactions.csv`** â€“ Customer engagement data, tracking clicks, signups, purchases, and acquisition costs.  \n",
        "3. **`synthetic_channel_performance.csv`** â€“ Channel effectiveness based on conversion rates and audience reach.  \n",
        "4. **`synthetic_roi_forecast.csv`** â€“ Predicted marketing budget performance for the next 6 months.  \n",
        "\n"
      ],
      "metadata": {
        "id": "2vha6DY_tJ55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Generating Financial Budget and Variance Data**  \n",
        "\n",
        "This script generates **structured financial budget data** across multiple departments. It includes:  \n",
        "\n",
        "1. **Budget vs. Actual Spending** â€“ Simulating financial data to track planned and actual expenses.  \n",
        "2. **Departmental Financial Data** â€“ Budget allocation for HR, IT, Marketing, Operations, R&D, etc.  \n",
        "3. **Variance Analysis Data** â€“ Identifying major overspending or savings patterns.  \n",
        "4. **Financial Forecasting** â€“ Predicting future expenses based on historical spending trends.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python"
      ],
      "metadata": {
        "id": "FEUOTD4EuAbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Departments and Expense Categories\n",
        "departments = [\"HR\", \"IT\", \"Marketing\", \"Operations\", \"R&D\", \"Finance\"]\n",
        "expense_categories = [\"Salaries\", \"Software Licenses\", \"Advertising\", \"Utilities\", \"Travel\", \"Consulting\", \"Equipment\"]\n",
        "months = pd.date_range(start=\"2023-01-01\", periods=12, freq='ME').strftime(\"%Y-%m\")\n",
        "\n",
        "# Generate Budget Data\n",
        "def generate_budget_data():\n",
        "    budget_data = []\n",
        "\n",
        "    for dept in departments:\n",
        "        for category in expense_categories:\n",
        "            for month in months:\n",
        "                budget_amount = np.random.randint(5000, 50000)  # Budget range\n",
        "                budget_data.append([dept, category, month, budget_amount])\n",
        "\n",
        "    return pd.DataFrame(budget_data, columns=[\"Department\", \"Expense_Category\", \"Month\", \"Budget_Amount\"])\n",
        "\n",
        "# Generate Actual Spending Data (with variance)\n",
        "def generate_actual_spending(budget_df):\n",
        "    actual_data = []\n",
        "\n",
        "    for index, row in budget_df.iterrows():\n",
        "        variance = np.random.uniform(-0.3, 0.3)  # Up to Â±30% variation\n",
        "        actual_amount = int(row[\"Budget_Amount\"] * (1 + variance))\n",
        "        actual_data.append([row[\"Department\"], row[\"Expense_Category\"], row[\"Month\"], actual_amount])\n",
        "\n",
        "    return pd.DataFrame(actual_data, columns=[\"Department\", \"Expense_Category\", \"Month\", \"Actual_Amount\"])\n",
        "\n",
        "# Generate Forecast Data (based on historical spending trends)\n",
        "def generate_forecast_data(actual_df):\n",
        "    forecast_data = []\n",
        "\n",
        "    for dept in departments:\n",
        "        for category in expense_categories:\n",
        "            for i in range(6):  # Forecast for next 6 months\n",
        "                forecast_month = (datetime.today() + timedelta(days=30 * (i+1))).strftime(\"%Y-%m\")\n",
        "                historical_avg = actual_df[\n",
        "                    (actual_df[\"Department\"] == dept) &\n",
        "                    (actual_df[\"Expense_Category\"] == category)\n",
        "                ][\"Actual_Amount\"].mean()\n",
        "\n",
        "                projected_amount = int(historical_avg * np.random.uniform(0.95, 1.1))  # Small random variation\n",
        "                forecast_data.append([dept, category, forecast_month, projected_amount])\n",
        "\n",
        "    return pd.DataFrame(forecast_data, columns=[\"Department\", \"Expense_Category\", \"Month\", \"Projected_Amount\"])\n",
        "\n",
        "# Generate Variance Data (Budget vs. Actual)\n",
        "def calculate_variance(budget_df, actual_df):\n",
        "    merged_df = budget_df.merge(actual_df, on=[\"Department\", \"Expense_Category\", \"Month\"])\n",
        "    merged_df[\"Variance\"] = merged_df[\"Actual_Amount\"] - merged_df[\"Budget_Amount\"]\n",
        "    merged_df[\"Variance_%\"] = (merged_df[\"Variance\"] / merged_df[\"Budget_Amount\"]) * 100\n",
        "    return merged_df\n",
        "\n",
        "# Generate DataFrames\n",
        "budget_df = generate_budget_data()\n",
        "actual_df = generate_actual_spending(budget_df)\n",
        "forecast_df = generate_forecast_data(actual_df)\n",
        "variance_df = calculate_variance(budget_df, actual_df)\n",
        "\n",
        "# Save to CSV\n",
        "budget_df.to_csv(\"financial_budget_data.csv\", index=False)\n",
        "actual_df.to_csv(\"actual_spending_data.csv\", index=False)\n",
        "forecast_df.to_csv(\"financial_forecast_data.csv\", index=False)\n",
        "variance_df.to_csv(\"variance_analysis_data.csv\", index=False)\n",
        "\n",
        "print(\"Financial budget dataset successfully generated and saved!\")\n"
      ],
      "metadata": {
        "id": "hhH_0zK9tIbP",
        "outputId": "9926e217-215e-4720-dda4-fc4a38605012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Financial budget dataset successfully generated and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Generated Datasets**\n",
        "1. **`financial_budget_data.csv`** â€“ Planned budget allocations for each department and expense category.  \n",
        "2. **`actual_spending_data.csv`** â€“ Real expenditure data with natural variance from budgeted amounts.  \n",
        "3. **`variance_analysis_data.csv`** â€“ Comparison of actual vs. planned spending, with variance calculations.  \n",
        "4. **`financial_forecast_data.csv`** â€“ Projected future expenses based on past spending trends.  "
      ],
      "metadata": {
        "id": "F_2YrSM_uDiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script for Generating Customer Segmentation and Lifetime Value (CLV) Dataset**  \n",
        "\n",
        "This script generates **structured customer transaction data** for customer segmentation and lifetime value analysis.  \n",
        "\n",
        "### **Features of the Dataset**  \n",
        "- **Customer Demographics**: Age, gender, location, and membership type.  \n",
        "- **Purchase Behavior**: Purchase frequency, average order value, and total spend.  \n",
        "- **Recency-Frequency-Monetary (RFM) Metrics**: Used for customer segmentation.  \n",
        "- **Churn & Retention Trends**: Predicting loyalty and future purchases.  \n",
        "- **Product Categories**: Mapping customers to different spending patterns.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python"
      ],
      "metadata": {
        "id": "9WO6pYlsum_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Customer Segments\n",
        "customer_segments = [\"High-Value\", \"Mid-Value\", \"Low-Value\", \"New\"]\n",
        "product_categories = [\"Electronics\", \"Clothing\", \"Groceries\", \"Furniture\", \"Toys\", \"Books\"]\n",
        "membership_types = [\"Premium\", \"Standard\", \"Basic\"]\n",
        "\n",
        "# Generate Customers Data\n",
        "num_customers = 500\n",
        "customers = []\n",
        "\n",
        "np.random.seed(42)  # Ensuring reproducibility\n",
        "\n",
        "for i in range(1, num_customers + 1):\n",
        "    customer_id = f\"CUST{i:04d}\"\n",
        "    age = np.random.randint(18, 65)\n",
        "    gender = np.random.choice([\"Male\", \"Female\"])\n",
        "    location = np.random.choice([\"Urban\", \"Suburban\", \"Rural\"])\n",
        "    membership = np.random.choice(membership_types, p=[0.3, 0.5, 0.2])\n",
        "    segment = np.random.choice(customer_segments, p=[0.2, 0.4, 0.3, 0.1])\n",
        "\n",
        "    customers.append([customer_id, age, gender, location, membership, segment])\n",
        "\n",
        "customers_df = pd.DataFrame(customers, columns=[\"Customer_ID\", \"Age\", \"Gender\", \"Location\", \"Membership_Type\", \"Segment\"])\n",
        "\n",
        "# Generate Transaction Data\n",
        "transactions = []\n",
        "start_date = datetime(2022, 1, 1)\n",
        "end_date = datetime(2024, 3, 1)\n",
        "\n",
        "for customer in customers_df[\"Customer_ID\"]:\n",
        "    num_transactions = np.random.randint(1, 20)  # Each customer has 1 to 20 transactions\n",
        "\n",
        "    for _ in range(num_transactions):\n",
        "        purchase_date = start_date + timedelta(days=np.random.randint(0, (end_date - start_date).days))\n",
        "        product = np.random.choice(product_categories)\n",
        "        amount_spent = np.random.randint(20, 1000)  # Order value\n",
        "        quantity = np.random.randint(1, 5)\n",
        "\n",
        "        transactions.append([customer, purchase_date, product, amount_spent, quantity])\n",
        "\n",
        "transactions_df = pd.DataFrame(transactions, columns=[\"Customer_ID\", \"Purchase_Date\", \"Product_Category\", \"Amount_Spent\", \"Quantity\"])\n",
        "\n",
        "# Calculate RFM Metrics\n",
        "latest_date = transactions_df[\"Purchase_Date\"].max()\n",
        "rfm_data = transactions_df.groupby(\"Customer_ID\").agg({\n",
        "    \"Purchase_Date\": lambda x: (latest_date - x.max()).days,  # Recency: Days since last purchase\n",
        "    \"Customer_ID\": \"count\",  # Frequency: Total number of purchases\n",
        "    \"Amount_Spent\": \"sum\"  # Monetary: Total amount spent\n",
        "})#.reset_index(drop=False) #Commented out this line\n",
        "\n",
        "#Rename the columns to avoid name conflict when resetting index. The index is also Customer_ID\n",
        "rfm_data.columns = [\"Recency\", \"Frequency\", \"Monetary\"]\n",
        "#Reset the index to make Customer_ID a regular column\n",
        "rfm_data = rfm_data.reset_index() # drop is True by default\n",
        "\n",
        "# Assign Customer Lifetime Value (CLV) Score\n",
        "# Add a small value to 'Recency' to avoid division by zero\n",
        "rfm_data[\"Recency\"] = rfm_data[\"Recency\"] + 0.001  # Prevents division by zero\n",
        "rfm_data[\"CLV\"] = (rfm_data[\"Frequency\"] * rfm_data[\"Monetary\"]) / rfm_data[\"Recency\"]\n",
        "rfm_data[\"CLV_Score\"] = pd.qcut(rfm_data[\"CLV\"], 4, labels=[\"Low\", \"Mid\", \"High\", \"Very High\"], duplicates='drop')\n",
        "\n",
        "# Merge RFM with Customer Data\n",
        "final_df = customers_df.merge(rfm_data, on=\"Customer_ID\")\n",
        "\n",
        "# Save CSV files\n",
        "customers_df.to_csv(\"customers_data.csv\", index=False)\n",
        "transactions_df.to_csv(\"transactions_data.csv\", index=False)\n",
        "rfm_data.to_csv(\"customer_rfm_data.csv\", index=False)\n",
        "final_df.to_csv(\"customer_segmentation_data.csv\", index=False)\n",
        "\n",
        "print(\"Customer segmentation dataset successfully generated!\")\n"
      ],
      "metadata": {
        "id": "Bupvg5RcuGY7",
        "outputId": "5ec5a59d-b895-4214-b40f-ee8c103274b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer segmentation dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**  \n",
        "1. **`customers_data.csv`** â€“ Customer demographic details with membership and segmentation.  \n",
        "2. **`transactions_data.csv`** â€“ Purchase history linked to customers and product categories.  \n",
        "3. **`customer_rfm_data.csv`** â€“ RFM analysis results for customer segmentation.  \n",
        "4. **`customer_segmentation_data.csv`** â€“ Final dataset linking customer details with purchase patterns.  \n",
        "\n"
      ],
      "metadata": {
        "id": "OirnKpmMuvnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Production Performance & Quality Control Dataset**  \n",
        "\n",
        "This script generates **structured manufacturing data** for **production performance analysis and quality control**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "- **Production Line Details**: Different production lines and shifts.  \n",
        "- **Product Categories**: Manufactured product types.  \n",
        "- **Quality Metrics**: Defect rates, yield, and overall equipment effectiveness (OEE).  \n",
        "- **Operational Efficiency**: Production output, downtime, and defective units.  \n",
        "- **Forecasting Variables**: Time-series trends for production optimization.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Production Line Details\n",
        "production_lines = [\"Line A\", \"Line B\", \"Line C\", \"Line D\"]\n",
        "product_types = [\"Gadget\", \"Component\", \"Device\", \"Tool\"]\n",
        "defect_categories = [\"Crack\", \"Misalignment\", \"Surface Defect\", \"Size Deviation\", \"Other\"]\n",
        "shifts = [\"Morning\", \"Evening\", \"Night\"]\n",
        "\n",
        "# Generate Production Data\n",
        "num_days = 180  # Number of days for historical data\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "production_data = []\n",
        "np.random.seed(42)  # Ensuring reproducibility\n",
        "\n",
        "for day in range(num_days):\n",
        "    production_date = start_date + timedelta(days=day)\n",
        "\n",
        "    for line in production_lines:\n",
        "        for shift in shifts:\n",
        "            product = np.random.choice(product_types)\n",
        "            total_output = np.random.randint(500, 5000)  # Units produced\n",
        "            defective_units = np.random.randint(5, 200)  # Defective products\n",
        "            downtime = np.random.randint(0, 120)  # Downtime in minutes\n",
        "            \n",
        "            yield_rate = (total_output - defective_units) / total_output * 100  # Yield %\n",
        "            defect_rate = (defective_units / total_output) * 100  # Defect rate\n",
        "            oee = np.random.uniform(60, 95)  # Overall Equipment Effectiveness\n",
        "            \n",
        "            production_data.append([production_date, line, shift, product, total_output, defective_units, yield_rate, defect_rate, downtime, oee])\n",
        "\n",
        "# Create DataFrame\n",
        "production_df = pd.DataFrame(production_data, columns=[\n",
        "    \"Date\", \"Production_Line\", \"Shift\", \"Product\", \"Total_Output\", \"Defective_Units\", \"Yield_Rate\", \"Defect_Rate\", \"Downtime_Minutes\", \"OEE\"\n",
        "])\n",
        "\n",
        "# Generate Defect Data\n",
        "defect_data = []\n",
        "for index, row in production_df.iterrows():\n",
        "    num_defects = np.random.randint(1, 5)  # 1 to 4 defect types per shift\n",
        "\n",
        "    for _ in range(num_defects):\n",
        "        defect_type = np.random.choice(defect_categories)\n",
        "        defect_count = np.random.randint(1, int(row[\"Defective_Units\"] / num_defects) + 1)\n",
        "\n",
        "        defect_data.append([row[\"Date\"], row[\"Production_Line\"], row[\"Shift\"], row[\"Product\"], defect_type, defect_count])\n",
        "\n",
        "# Create DataFrame for defects\n",
        "defect_df = pd.DataFrame(defect_data, columns=[\"Date\", \"Production_Line\", \"Shift\", \"Product\", \"Defect_Type\", \"Defect_Count\"])\n",
        "\n",
        "# Save CSV Files\n",
        "production_df.to_csv(\"production_data.csv\", index=False)\n",
        "defect_df.to_csv(\"defect_data.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic production performance dataset successfully generated!\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Generated Datasets**\n",
        "1. **`production_data.csv`**  \n",
        "   - Date, production line, shift, product, total output, defective units, yield rate, defect rate, downtime, OEE.  \n",
        "2. **`defect_data.csv`**  \n",
        "   - Date, production line, shift, product, defect type, defect count.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Next Steps**\n",
        "Would you like to **add predictive modeling features**, such as **forecasting production efficiency or defect reduction trends**? ðŸš€"
      ],
      "metadata": {
        "id": "Yuuj20eNw2RT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Production Performance & Quality Control Dataset**  \n",
        "\n",
        "This script generates **structured manufacturing data** for **production performance analysis and quality control**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "- **Production Line Details**: Different production lines and shifts.  \n",
        "- **Product Categories**: Manufactured product types.  \n",
        "- **Quality Metrics**: Defect rates, yield, and overall equipment effectiveness (OEE).  \n",
        "- **Operational Efficiency**: Production output, downtime, and defective units.  \n",
        "- **Forecasting Variables**: Time-series trends for production optimization.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**\n",
        "```python\n"
      ],
      "metadata": {
        "id": "41A1DlPzw7YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Production Line Details\n",
        "production_lines = [\"Line A\", \"Line B\", \"Line C\", \"Line D\"]\n",
        "product_types = [\"Gadget\", \"Component\", \"Device\", \"Tool\"]\n",
        "defect_categories = [\"Crack\", \"Misalignment\", \"Surface Defect\", \"Size Deviation\", \"Other\"]\n",
        "shifts = [\"Morning\", \"Evening\", \"Night\"]\n",
        "\n",
        "# Generate Production Data\n",
        "num_days = 180  # Number of days for historical data\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "production_data = []\n",
        "np.random.seed(42)  # Ensuring reproducibility\n",
        "\n",
        "for day in range(num_days):\n",
        "    production_date = start_date + timedelta(days=day)\n",
        "\n",
        "    for line in production_lines:\n",
        "        for shift in shifts:\n",
        "            product = np.random.choice(product_types)\n",
        "            total_output = np.random.randint(500, 5000)  # Units produced\n",
        "            defective_units = np.random.randint(5, 200)  # Defective products\n",
        "            downtime = np.random.randint(0, 120)  # Downtime in minutes\n",
        "\n",
        "            yield_rate = (total_output - defective_units) / total_output * 100  # Yield %\n",
        "            defect_rate = (defective_units / total_output) * 100  # Defect rate\n",
        "            oee = np.random.uniform(60, 95)  # Overall Equipment Effectiveness\n",
        "\n",
        "            production_data.append([production_date, line, shift, product, total_output, defective_units, yield_rate, defect_rate, downtime, oee])\n",
        "\n",
        "# Create DataFrame\n",
        "production_df = pd.DataFrame(production_data, columns=[\n",
        "    \"Date\", \"Production_Line\", \"Shift\", \"Product\", \"Total_Output\", \"Defective_Units\", \"Yield_Rate\", \"Defect_Rate\", \"Downtime_Minutes\", \"OEE\"\n",
        "])\n",
        "\n",
        "# Generate Defect Data\n",
        "defect_data = []\n",
        "for index, row in production_df.iterrows():\n",
        "    num_defects = np.random.randint(1, 5)  # 1 to 4 defect types per shift\n",
        "\n",
        "    for _ in range(num_defects):\n",
        "        defect_type = np.random.choice(defect_categories)\n",
        "        defect_count = np.random.randint(1, int(row[\"Defective_Units\"] / num_defects) + 1)\n",
        "\n",
        "        defect_data.append([row[\"Date\"], row[\"Production_Line\"], row[\"Shift\"], row[\"Product\"], defect_type, defect_count])\n",
        "\n",
        "# Create DataFrame for defects\n",
        "defect_df = pd.DataFrame(defect_data, columns=[\"Date\", \"Production_Line\", \"Shift\", \"Product\", \"Defect_Type\", \"Defect_Count\"])\n",
        "\n",
        "# Save CSV Files\n",
        "production_df.to_csv(\"production_data.csv\", index=False)\n",
        "defect_df.to_csv(\"defect_data.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic production performance dataset successfully generated!\")"
      ],
      "metadata": {
        "id": "SQG4GlqIusrU",
        "outputId": "1fb37e97-6d7e-404d-b879-3db69139798c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic production performance dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**\n",
        "1. **`production_data.csv`**  \n",
        "   - Date, production line, shift, product, total output, defective units, yield rate, defect rate, downtime, OEE.  \n",
        "2. **`defect_data.csv`**  \n",
        "   - Date, production line, shift, product, defect type, defect count.  "
      ],
      "metadata": {
        "id": "YF6DHnrDxDtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Project Portfolio Management Dataset**  \n",
        "\n",
        "This script generates **structured project management data** for **tracking multiple projects, analyzing performance metrics, and optimizing resource allocation**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "- **Project Details**: Project names, departments, and priority levels.  \n",
        "- **Resource Allocation**: Assigned team members, hours allocated, and budget details.  \n",
        "- **Performance Metrics**: Schedule variance, cost performance index (CPI), and risk level.  \n",
        "- **Forecasting Variables**: Completion percentage trends and resource utilization.  \n",
        "- **What-If Analysis**: Data to support resource allocation planning.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "-dSbq3tnxcl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Project Details\n",
        "departments = [\"IT\", \"Finance\", \"Marketing\", \"Operations\", \"HR\"]\n",
        "project_names = [\"Alpha\", \"Beta\", \"Gamma\", \"Delta\", \"Epsilon\", \"Zeta\", \"Theta\", \"Sigma\", \"Omega\"]\n",
        "project_priorities = [\"High\", \"Medium\", \"Low\"]\n",
        "statuses = [\"On Track\", \"Delayed\", \"At Risk\", \"Completed\"]\n",
        "resources = [\"Developer\", \"Analyst\", \"Designer\", \"Manager\", \"Tester\"]\n",
        "\n",
        "# Generate Project Data\n",
        "num_projects = 50  # Number of projects\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "project_data = []\n",
        "np.random.seed(42)  # Ensuring reproducibility\n",
        "\n",
        "for i in range(num_projects):\n",
        "    project_id = f\"PJT-{1000 + i}\"\n",
        "    project_name = np.random.choice(project_names)\n",
        "    department = np.random.choice(departments)\n",
        "    priority = np.random.choice(project_priorities, p=[0.4, 0.4, 0.2])  # More High & Medium priority projects\n",
        "    status = np.random.choice(statuses, p=[0.5, 0.2, 0.2, 0.1])  # Most projects are On Track\n",
        "    start_date_project = start_date + timedelta(days=np.random.randint(0, 365))  # Random start dates in the past year\n",
        "    duration_days = np.random.randint(30, 365)  # Project duration between 1 month and 1 year\n",
        "    end_date_project = start_date_project + timedelta(days=duration_days)\n",
        "    completion_percentage = np.random.randint(10, 100) if status != \"Completed\" else 100\n",
        "    budget_allocated = np.random.randint(10000, 100000)\n",
        "    budget_used = budget_allocated * np.random.uniform(0.5, 1.2)  # Budget usage could be over or under\n",
        "    schedule_variance = np.random.uniform(-20, 20)  # Positive: Ahead, Negative: Behind schedule\n",
        "    cpi = np.random.uniform(0.8, 1.2)  # Cost Performance Index (CPI)\n",
        "    risk_level = np.random.choice([\"Low\", \"Medium\", \"High\"], p=[0.5, 0.3, 0.2])  # Majority Low Risk\n",
        "\n",
        "    project_data.append([\n",
        "        project_id, project_name, department, priority, status, start_date_project,\n",
        "        end_date_project, duration_days, completion_percentage, budget_allocated,\n",
        "        budget_used, schedule_variance, cpi, risk_level\n",
        "    ])\n",
        "\n",
        "# Create DataFrame\n",
        "project_df = pd.DataFrame(project_data, columns=[\n",
        "    \"Project_ID\", \"Project_Name\", \"Department\", \"Priority\", \"Status\", \"Start_Date\",\n",
        "    \"End_Date\", \"Duration_Days\", \"Completion_Percentage\", \"Budget_Allocated\",\n",
        "    \"Budget_Used\", \"Schedule_Variance\", \"CPI\", \"Risk_Level\"\n",
        "])\n",
        "\n",
        "# Generate Resource Allocation Data\n",
        "resource_data = []\n",
        "for project_id in project_df[\"Project_ID\"]:\n",
        "    num_resources = np.random.randint(2, 6)  # 2 to 5 resources per project\n",
        "    for _ in range(num_resources):\n",
        "        resource_type = np.random.choice(resources)\n",
        "        hours_allocated = np.random.randint(50, 500)  # Resource hours allocated\n",
        "        resource_cost = hours_allocated * np.random.randint(20, 100)  # Hourly cost\n",
        "\n",
        "        resource_data.append([project_id, resource_type, hours_allocated, resource_cost])\n",
        "\n",
        "# Create DataFrame for Resources\n",
        "resource_df = pd.DataFrame(resource_data, columns=[\"Project_ID\", \"Resource_Type\", \"Hours_Allocated\", \"Resource_Cost\"])\n",
        "\n",
        "# Save CSV Files\n",
        "project_df.to_csv(\"project_data.csv\", index=False)\n",
        "resource_df.to_csv(\"resource_allocation.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic project portfolio dataset successfully generated!\")\n"
      ],
      "metadata": {
        "id": "tr1MK9SjxEFA",
        "outputId": "9fb788e9-a855-490b-b18f-3a92d43b0630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic project portfolio dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Generated Datasets**\n",
        "1. **`project_data.csv`**  \n",
        "   - Project ID, Name, Department, Priority, Status, Start & End Dates, Budget, Schedule Variance, CPI, Risk Level, etc.  \n",
        "2. **`resource_allocation.csv`**  \n",
        "   - Project ID, Assigned Resource, Hours Allocated, Resource Cost.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Next Steps**\n",
        "Would you like to **integrate predictive modeling** to forecast **project completion delays or cost overruns**? ðŸš€"
      ],
      "metadata": {
        "id": "SJIYVa1Vxj8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Sales Territory and Commission Analysis Dataset**  \n",
        "\n",
        "This script generates **structured sales data** to support **territory performance analysis, commission tracking, and sales forecasting**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "- **Sales Transactions**: Orders, product categories, and sales amounts.  \n",
        "- **Sales Representatives**: Assigned territories, individual quotas, and commissions.  \n",
        "- **Performance Metrics**: Quota attainment, commission earnings, and regional contributions.  \n",
        "- **Forecasting Variables**: Sales trends, historical growth, and seasonal patterns.  \n",
        "- **What-If Analysis**: Scenario planning for commission structures and sales targets.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "xc4pbQlFx20K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Sales Territories and Representatives\n",
        "territories = [\"North\", \"South\", \"East\", \"West\", \"Central\"]\n",
        "sales_reps = [\"John Doe\", \"Jane Smith\", \"Mike Brown\", \"Sarah Lee\", \"Tom Wilson\"]\n",
        "products = [\"Product A\", \"Product B\", \"Product C\", \"Product D\", \"Product E\"]\n",
        "commission_rates = {\"Product A\": 0.05, \"Product B\": 0.06, \"Product C\": 0.07, \"Product D\": 0.08, \"Product E\": 0.09}\n",
        "\n",
        "# Generate Sales Transactions\n",
        "num_sales = 1000  # Number of sales records\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "sales_data = []\n",
        "np.random.seed(42)  # Ensuring reproducibility\n",
        "\n",
        "for i in range(num_sales):\n",
        "    order_id = f\"ORD-{1000 + i}\"\n",
        "    sales_rep = np.random.choice(sales_reps)\n",
        "    territory = np.random.choice(territories)\n",
        "    product = np.random.choice(products)\n",
        "    order_date = start_date + timedelta(days=np.random.randint(0, 365))  # Random order dates in the past year\n",
        "    quantity = np.random.randint(1, 10)  # Number of products sold\n",
        "    unit_price = np.random.randint(50, 500)  # Price per unit\n",
        "    total_sales = quantity * unit_price\n",
        "    commission_rate = commission_rates[product]\n",
        "    commission_earned = total_sales * commission_rate\n",
        "\n",
        "    sales_data.append([\n",
        "        order_id, order_date, sales_rep, territory, product, quantity, unit_price,\n",
        "        total_sales, commission_rate, commission_earned\n",
        "    ])\n",
        "\n",
        "# Create DataFrame for Sales Data\n",
        "sales_df = pd.DataFrame(sales_data, columns=[\n",
        "    \"Order_ID\", \"Order_Date\", \"Sales_Rep\", \"Territory\", \"Product\", \"Quantity\",\n",
        "    \"Unit_Price\", \"Total_Sales\", \"Commission_Rate\", \"Commission_Earned\"\n",
        "])\n",
        "\n",
        "# Generate Sales Representative Performance Data\n",
        "rep_performance_data = []\n",
        "for rep in sales_reps:\n",
        "    territory = np.random.choice(territories)\n",
        "    total_sales_rep = sales_df[sales_df[\"Sales_Rep\"] == rep][\"Total_Sales\"].sum()\n",
        "    commission_earned_rep = sales_df[sales_df[\"Sales_Rep\"] == rep][\"Commission_Earned\"].sum()\n",
        "    quota_target = total_sales_rep * np.random.uniform(0.8, 1.2)  # Quota set around total sales achieved\n",
        "    quota_attainment = (total_sales_rep / quota_target) * 100\n",
        "\n",
        "    rep_performance_data.append([rep, territory, total_sales_rep, quota_target, quota_attainment, commission_earned_rep])\n",
        "\n",
        "# Create DataFrame for Sales Representatives Performance\n",
        "rep_performance_df = pd.DataFrame(rep_performance_data, columns=[\n",
        "    \"Sales_Rep\", \"Territory\", \"Total_Sales\", \"Quota_Target\", \"Quota_Attainment\", \"Commission_Earned\"\n",
        "])\n",
        "\n",
        "# Save CSV Files\n",
        "sales_df.to_csv(\"sales_data.csv\", index=False)\n",
        "rep_performance_df.to_csv(\"sales_rep_performance.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic sales and commission analysis dataset successfully generated!\")"
      ],
      "metadata": {
        "id": "Sm_3xC_txjTy",
        "outputId": "1b8bc6a4-9304-45fa-9b40-b60bafae2518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic sales and commission analysis dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**\n",
        "1. **`sales_data.csv`**  \n",
        "   - Order ID, Date, Sales Representative, Territory, Product, Quantity, Unit Price, Total Sales, Commission Rate, and Commission Earned.  \n",
        "2. **`sales_rep_performance.csv`**  \n",
        "   - Sales Representative, Territory, Total Sales, Quota Target, Quota Attainment %, and Total Commission Earned.  \n"
      ],
      "metadata": {
        "id": "b8MwJ5wMx8kH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate Synthetic Healthcare Operations and Patient Analytics Dataset**  \n",
        "\n",
        "This script creates **structured healthcare data** for **patient flow tracking, operational performance analysis, and capacity planning.**  \n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "- **Patient Admissions**: Patient demographics, hospital admissions, length of stay.  \n",
        "- **Operational Metrics**: Staff availability, department utilization, readmission rates.  \n",
        "- **Forecasting Variables**: Admission trends, seasonal patterns, length of stay distributions.  \n",
        "- **What-If Analysis**: Scenario planning for hospital capacity and staffing needs.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "pePdck7VyPDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Healthcare Departments and Procedures\n",
        "departments = [\"Emergency\", \"ICU\", \"Surgery\", \"Maternity\", \"Pediatrics\", \"Oncology\"]\n",
        "procedures = [\"MRI Scan\", \"CT Scan\", \"Knee Surgery\", \"Appendectomy\", \"C-Section\", \"Chemotherapy\"]\n",
        "\n",
        "# Define patient demographics\n",
        "genders = [\"Male\", \"Female\", \"Other\"]\n",
        "age_groups = {\"Child\": (0, 12), \"Teen\": (13, 19), \"Adult\": (20, 65), \"Senior\": (66, 90)}\n",
        "\n",
        "# Define staffing levels (doctors, nurses per department)\n",
        "staffing_levels = {\n",
        "    \"Emergency\": {\"Doctors\": 15, \"Nurses\": 30},\n",
        "    \"ICU\": {\"Doctors\": 10, \"Nurses\": 20},\n",
        "    \"Surgery\": {\"Doctors\": 20, \"Nurses\": 40},\n",
        "    \"Maternity\": {\"Doctors\": 12, \"Nurses\": 25},\n",
        "    \"Pediatrics\": {\"Doctors\": 10, \"Nurses\": 20},\n",
        "    \"Oncology\": {\"Doctors\": 8, \"Nurses\": 15},\n",
        "}\n",
        "\n",
        "# Generate Patient Admission Data\n",
        "num_patients = 1000\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "patient_data = []\n",
        "np.random.seed(42)\n",
        "\n",
        "for i in range(num_patients):\n",
        "    patient_id = f\"PAT-{1000 + i}\"\n",
        "    department = np.random.choice(departments)\n",
        "    procedure = np.random.choice(procedures)\n",
        "    gender = np.random.choice(genders)\n",
        "\n",
        "    # Randomly assign an age based on age group distribution\n",
        "    age_group = np.random.choice(list(age_groups.keys()))\n",
        "    age = np.random.randint(*age_groups[age_group])\n",
        "\n",
        "    admission_date = start_date + timedelta(days=np.random.randint(0, 365))\n",
        "    length_of_stay = np.random.randint(1, 15)\n",
        "    discharge_date = admission_date + timedelta(days=length_of_stay)\n",
        "    readmission = np.random.choice([0, 1], p=[0.85, 0.15])  # 15% readmission rate\n",
        "\n",
        "    patient_data.append([\n",
        "        patient_id, admission_date, discharge_date, gender, age, department,\n",
        "        procedure, length_of_stay, readmission\n",
        "    ])\n",
        "\n",
        "# Create DataFrame for Patient Data\n",
        "patient_df = pd.DataFrame(patient_data, columns=[\n",
        "    \"Patient_ID\", \"Admission_Date\", \"Discharge_Date\", \"Gender\", \"Age\", \"Department\",\n",
        "    \"Procedure\", \"Length_of_Stay\", \"Readmission\"\n",
        "])\n",
        "\n",
        "# Generate Department Staffing Data\n",
        "staffing_data = []\n",
        "for dept, staff in staffing_levels.items():\n",
        "    doctors = staff[\"Doctors\"]\n",
        "    nurses = staff[\"Nurses\"]\n",
        "    total_patients = patient_df[patient_df[\"Department\"] == dept].shape[0]\n",
        "    avg_length_of_stay = patient_df[patient_df[\"Department\"] == dept][\"Length_of_Stay\"].mean()\n",
        "\n",
        "    staffing_data.append([dept, doctors, nurses, total_patients, avg_length_of_stay])\n",
        "\n",
        "# Create DataFrame for Staffing Levels\n",
        "staffing_df = pd.DataFrame(staffing_data, columns=[\n",
        "    \"Department\", \"Doctors\", \"Nurses\", \"Total_Patients\", \"Avg_Length_of_Stay\"\n",
        "])\n",
        "\n",
        "# Save CSV Files\n",
        "patient_df.to_csv(\"patient_data.csv\", index=False)\n",
        "staffing_df.to_csv(\"staffing_data.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic healthcare dataset successfully generated!\")"
      ],
      "metadata": {
        "id": "lh2BGcXyx8_r",
        "outputId": "fe364c99-6086-4865-9ef6-bff249701ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic healthcare dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**\n",
        "1. **`patient_data.csv`**  \n",
        "   - Patient ID, Admission Date, Discharge Date, Gender, Age, Department, Procedure, Length of Stay, Readmission.  \n",
        "2. **`staffing_data.csv`**  \n",
        "   - Department, Number of Doctors, Number of Nurses, Total Patients, and Average Length of Stay.  "
      ],
      "metadata": {
        "id": "aMkjwAmpyWt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate a Personal Finance & Investment Tracker Dataset**  \n",
        "\n",
        "This script creates **structured financial data** for tracking income, expenses, savings, and investments.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "âœ… **Income & Expenses**: Track salaries, business income, utility bills, rent, shopping, and more.  \n",
        "âœ… **Investment Portfolio**: Stocks, mutual funds, cryptocurrencies, real estate, etc.  \n",
        "âœ… **Spending Trends**: Monthly trends, category-wise breakdowns, budget monitoring.  \n",
        "âœ… **Financial Planning**: Savings forecasts, retirement planning.  \n",
        "âœ… **Visualization & Dashboard Support**: Easily integrates with Excel for pivot tables and charts.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "u1tKfQWPypWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Categories for Income and Expenses\n",
        "income_sources = [\"Salary\", \"Freelance\", \"Business\", \"Investments\", \"Dividends\"]\n",
        "expense_categories = [\"Rent\", \"Groceries\", \"Utilities\", \"Transportation\", \"Entertainment\", \"Shopping\", \"Insurance\", \"Healthcare\"]\n",
        "\n",
        "# Define Investment Types\n",
        "investment_types = [\"Stocks\", \"Mutual Funds\", \"Crypto\", \"Real Estate\", \"Bonds\", \"ETF\"]\n",
        "\n",
        "# Generate Financial Transactions Data\n",
        "num_transactions = 500\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "transactions = []\n",
        "np.random.seed(42)\n",
        "\n",
        "for i in range(num_transactions):\n",
        "    trans_id = f\"TXN-{1000 + i}\"\n",
        "    date = start_date + timedelta(days=np.random.randint(0, 365))\n",
        "    trans_type = np.random.choice([\"Income\", \"Expense\"])\n",
        "\n",
        "    if trans_type == \"Income\":\n",
        "        category = np.random.choice(income_sources)\n",
        "        amount = np.random.randint(1000, 10000)  # Random income amounts\n",
        "    else:\n",
        "        category = np.random.choice(expense_categories)\n",
        "        amount = np.random.randint(50, 2000)  # Random expense amounts\n",
        "\n",
        "    transactions.append([trans_id, date, trans_type, category, amount])\n",
        "\n",
        "# Create DataFrame for Transactions\n",
        "transactions_df = pd.DataFrame(transactions, columns=[\"Transaction_ID\", \"Date\", \"Type\", \"Category\", \"Amount\"])\n",
        "\n",
        "# Generate Investment Portfolio Data\n",
        "num_investments = 100\n",
        "investments = []\n",
        "\n",
        "for i in range(num_investments):\n",
        "    inv_id = f\"INV-{2000 + i}\"\n",
        "    asset = np.random.choice(investment_types)\n",
        "    buy_date = start_date + timedelta(days=np.random.randint(0, 365))\n",
        "    buy_price = round(np.random.uniform(100, 5000), 2)  # Initial investment\n",
        "    current_price = buy_price * round(np.random.uniform(0.8, 1.5), 2)  # Simulated market fluctuation\n",
        "    quantity = np.random.randint(1, 50)\n",
        "\n",
        "    investments.append([inv_id, asset, buy_date, buy_price, current_price, quantity])\n",
        "\n",
        "# Create DataFrame for Investments\n",
        "investments_df = pd.DataFrame(investments, columns=[\"Investment_ID\", \"Asset_Type\", \"Buy_Date\", \"Buy_Price\", \"Current_Price\", \"Quantity\"])\n",
        "\n",
        "# Save CSV Files\n",
        "transactions_df.to_csv(\"financial_transactions.csv\", index=False)\n",
        "investments_df.to_csv(\"investment_portfolio.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic financial dataset successfully generated!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vSnsTs3vyWNf",
        "outputId": "e64e4085-eadc-40b4-cd0b-64c9d43d98fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic financial dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generated Datasets**\n",
        "1. **`financial_transactions.csv`**  \n",
        "   - **Income & Expenses** categorized by type, date, and amount.  \n",
        "2. **`investment_portfolio.csv`**  \n",
        "   - **Investments** with asset type, purchase price, and current valuation."
      ],
      "metadata": {
        "id": "mahdMR-_ywoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Script to Generate an Educational Performance & Learning Analytics Dataset**  \n",
        "\n",
        "This script creates **structured student performance data** for tracking grades, attendance, learning patterns, and interventions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features of the Dataset**  \n",
        "âœ… **Student Performance Tracking**: Scores, GPA trends, attendance records.  \n",
        "âœ… **Course & Assessment Data**: Exam scores, quiz performance, assignment completion rates.  \n",
        "âœ… **At-Risk Student Detection**: Identifies students needing interventions.  \n",
        "âœ… **Forecasting & What-If Analysis**: Predicts grades & success factors.  \n",
        "âœ… **Visualization & Dashboard Support**: Supports Excel pivot tables & interactive charts.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Python Script**  \n",
        "```python\n"
      ],
      "metadata": {
        "id": "6_PytrUozK6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define Course Subjects\n",
        "courses = [\"Mathematics\", \"Science\", \"History\", \"English\", \"Computer Science\", \"Physics\", \"Biology\", \"Economics\"]\n",
        "\n",
        "# Generate Student Data\n",
        "num_students = 200\n",
        "start_date = datetime(2023, 1, 1)\n",
        "\n",
        "students = []\n",
        "np.random.seed(42)\n",
        "\n",
        "for i in range(num_students):\n",
        "    student_id = f\"STU-{1000 + i}\"\n",
        "    name = f\"Student {i+1}\"\n",
        "    gender = np.random.choice([\"Male\", \"Female\"])\n",
        "    age = np.random.randint(15, 22)\n",
        "    attendance_rate = round(np.random.uniform(70, 100), 2)  # Attendance percentage\n",
        "    gpa = round(np.random.uniform(2.0, 4.0), 2)  # Random GPA between 2.0 - 4.0\n",
        "\n",
        "    students.append([student_id, name, gender, age, attendance_rate, gpa])\n",
        "\n",
        "# Create DataFrame for Students\n",
        "students_df = pd.DataFrame(students, columns=[\"Student_ID\", \"Name\", \"Gender\", \"Age\", \"Attendance_Rate\", \"GPA\"])\n",
        "\n",
        "# Generate Performance Data (Grades)\n",
        "num_records = 1000\n",
        "performance = []\n",
        "\n",
        "for i in range(num_records):\n",
        "    student_id = np.random.choice(students_df[\"Student_ID\"])\n",
        "    course = np.random.choice(courses)\n",
        "    assessment = np.random.choice([\"Quiz\", \"Assignment\", \"Midterm\", \"Final Exam\"])\n",
        "    score = np.random.randint(50, 100)  # Random score\n",
        "\n",
        "    performance.append([student_id, course, assessment, score])\n",
        "\n",
        "# Create DataFrame for Performance\n",
        "performance_df = pd.DataFrame(performance, columns=[\"Student_ID\", \"Course\", \"Assessment\", \"Score\"])\n",
        "\n",
        "# Save CSV Files\n",
        "students_df.to_csv(\"student_data.csv\", index=False)\n",
        "performance_df.to_csv(\"performance_data.csv\", index=False)\n",
        "\n",
        "print(\"Synthetic educational dataset successfully generated!\")\n"
      ],
      "metadata": {
        "id": "_mvqoywjywJj",
        "outputId": "12490491-53bb-4eb0-8693-f0d3fd6b60ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic educational dataset successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Generated Datasets**\n",
        "1. **`student_data.csv`**  \n",
        "   - **Student Demographics** (ID, Name, Age, Gender).  \n",
        "   - **Attendance & GPA** for tracking academic performance.  \n",
        "2. **`performance_data.csv`**  \n",
        "   - **Student Scores** by subject & assessment type.  "
      ],
      "metadata": {
        "id": "csqiUsltzSVR"
      }
    }
  ]
}